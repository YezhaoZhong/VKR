{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from networkx.algorithms.bipartite.matrix import biadjacency_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.utils import parallel_backend\n",
    "from itertools import product\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import svm\n",
    "random.seed(1949) \n",
    "np.random.seed(1949) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is for the study of ADRs prediction using SVM linear kernel. After the function in section 1 run, nested CV, CV and result of test set in section 2 can be ran separately."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the functions used for SVM-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def option(str):\n",
    "    global methodOption\n",
    "    methodOption = str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for SVM-linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def option2(tf):\n",
    "    global normalizationOption\n",
    "    normalizationOption = tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMloop(idx, X, X_new, y, y_new, Y_new, idx_test,c,g):\n",
    "    # print(idx)\n",
    "    # t = time.time()\n",
    "    y_i = np.array(y[idx, :].copy()).tolist()\n",
    "    if len(np.unique(y_i)) == 1:\n",
    "        Y_new[idx, idx_test] = np.unique(y_i)\n",
    "    else:\n",
    "\n",
    "        if (methodOption == \"SVMRBF1\") | (methodOption == \"SVMRBF2\") |  (methodOption == \"SVMRBF1&2\"):\n",
    "            svr = svm.SVR(kernel=\"rbf\", C = c, gamma = g).fit(X, y_i)\n",
    "\n",
    "        elif (methodOption == \"SVML1\") | (methodOption == \"SVML2\") |  (methodOption == \"SVML1&2\"):\n",
    "            svr = svm.SVR(kernel=\"linear\", C = c).fit(X, y_i)\n",
    "\n",
    "        p_labels = svr.predict(X_new)\n",
    "        Y_new[idx, idx_test] = p_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVMforAllSe(matrix, feature_matrix1, feature_matrix2, idx_train, idx_test, c, g):\n",
    "    if (methodOption == \"SVMRBF1\") | (methodOption == \"SVML1\"):\n",
    "        feature_matrix = feature_matrix1.copy()\n",
    "    elif (methodOption == \"SVMRBF2\") | (methodOption == \"SVML2\"):\n",
    "        feature_matrix = feature_matrix2.copy()\n",
    "    elif (methodOption == \"SVMRBF1&2\") | (methodOption == \"SVML1&2\"):\n",
    "        feature_matrix = np.array(pd.concat([pd.DataFrame(feature_matrix1), pd.DataFrame(feature_matrix2)], axis = 1))\n",
    "\n",
    "    if normalizationOption == True:\n",
    "        feature_matrix = (feature_matrix.copy() - feature_matrix.mean()) / feature_matrix.std()\n",
    "    X = np.array(feature_matrix[idx_train, :].copy()).tolist()\n",
    "    X_new = np.array(feature_matrix[idx_test, :].copy()).tolist()\n",
    "    y = matrix[:, idx_train].copy()\n",
    "    y_new = matrix[:, idx_test].copy()\n",
    "    global Y_new\n",
    "    Y_new = matrix.copy().astype(float)\n",
    "\n",
    "    m,n = matrix.shape \n",
    "    \n",
    "    with parallel_backend('threading'):\n",
    "        Parallel(n_jobs=5000)(delayed(SVMloop)(idx = i , X=X, X_new=X_new, y=y, y_new=y_new, Y_new=Y_new, \\\n",
    "            idx_test=idx_test,c=c,g=g) for i in range(m))\n",
    "    \n",
    "    \n",
    "    return Y_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for generating features for common drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeaturePreprocess(df_all, drug_nodes):\n",
    "    \n",
    "    drug_nodes_df = np.intersect1d(df_all.index, drug_nodes)\n",
    "    df = df_all.loc[drug_nodes_df]\n",
    "    _, q = df.shape\n",
    "    drug_nodes_diff = np.setdiff1d(drug_nodes, (df.index).tolist())\n",
    "    n = len(drug_nodes_diff)\n",
    "    df_diff = pd.DataFrame(np.zeros(n*q).reshape(n,q))\n",
    "    df_diff.index = drug_nodes_diff\n",
    "    df_diff.columns = df.columns\n",
    "    df_all = pd.concat([df, df_diff], axis = 0)\n",
    "    featureMat = df_all.loc[drug_nodes]\n",
    "    return np.array(featureMat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for cross validation and nested cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold(IDX1,IDX2,feature_matrix1,feature_matrix2,matrix,c,g):\n",
    "    # IDX1 target index, need to be evaluated\n",
    "    # IDX2 test index, masked\n",
    "    target_idx = IDX1\n",
    "    mask_idx = IDX2\n",
    "    Ground_Truth = matrix.copy()\n",
    "    side_effects_drug_relation_copy = matrix.copy()\n",
    "\n",
    "    # target_idx = IDX2\n",
    "    ### making all the links to predict as 0 ###############    \n",
    "    for i in range(len(mask_idx)):\n",
    "        side_effects_drug_relation_copy[:, mask_idx[i]] = 0\n",
    "    \n",
    "    m,n = side_effects_drug_relation_copy.shape\n",
    "\n",
    "    drug_idx = list(range(n))\n",
    "    existing_drug_idx = np.setdiff1d(drug_idx, mask_idx)\n",
    "    \n",
    "    print(methodOption + ' starts:')\n",
    "    side_effects_drug_relation_fact = SVMforAllSe(matrix=matrix, feature_matrix1=feature_matrix1, feature_matrix2=feature_matrix2, idx_train=existing_drug_idx, idx_test=target_idx, c=c, g=g)\n",
    "    # sys.stdout = real_stdout\n",
    "    print(methodOption + ' ends:')\n",
    "\n",
    "\n",
    "    # Set the out put of GNMF as prediction score\n",
    "    score = side_effects_drug_relation_fact.copy()\n",
    "    # score = score_mean.copy()\n",
    "\n",
    "    \n",
    "    pr_auc_all = 0\n",
    "    roc_auc_all = 0\n",
    "    \n",
    "\n",
    "    print(\"proportion of ground truth:\", sum(Ground_Truth[:, target_idx].ravel())/(Ground_Truth[:, target_idx].shape[0]*Ground_Truth[:, target_idx].shape[1]))\n",
    "\n",
    "    print('---evaluation---')\n",
    "    prec, recall, threshold = precision_recall_curve(Ground_Truth[:, target_idx].ravel(), score[:, target_idx].ravel())\n",
    "    pr_auc_all = auc(recall, prec)\n",
    "    roc_auc_all = roc_auc_score(Ground_Truth[:, target_idx].ravel(), score[:, target_idx].ravel())\n",
    "\n",
    "\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "    print(\"AUC-PR all:\", pr_auc_all)\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "    print(\"AUC-ROC all:\", roc_auc_all)\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "    return pr_auc_all, roc_auc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innerfold(IDX1,IDX2,feature_matrix1,feature_matrix2,matrix,c,g):\n",
    "    # IDX1 target index, need to be evaluated\n",
    "    # IDX2 test index, masked\n",
    "\n",
    "    target_idx = IDX1\n",
    "    mask_idx = IDX2\n",
    "    Ground_Truth = matrix.copy()\n",
    "    side_effects_drug_relation_copy = matrix.copy()\n",
    "\n",
    "    # target_idx = IDX2\n",
    "    ### making all the links to predict as 0 ###############    \n",
    "    for i in range(len(mask_idx)):\n",
    "        side_effects_drug_relation_copy[:, mask_idx[i]] = 0\n",
    "    \n",
    "    m,n = side_effects_drug_relation_copy.shape\n",
    "\n",
    "    drug_idx = list(range(n))\n",
    "    existing_drug_idx = np.setdiff1d(drug_idx, mask_idx)\n",
    "    \n",
    "    # calculate the mean for each drug\n",
    "    mean_side_effect_score = (Ground_Truth.copy()[:, existing_drug_idx]).mean(axis=1)\n",
    "    score_mean = side_effects_drug_relation_copy.copy().astype(float)\n",
    "\n",
    "    # Set the prediction into mean\n",
    "    for i in range(m):\n",
    "        score_mean[i, mask_idx] =  mean_side_effect_score[i]\n",
    "\n",
    "\n",
    "    side_effects_drug_relation_fact = SVMforAllSe(matrix=matrix, feature_matrix1=feature_matrix1, feature_matrix2=feature_matrix2, idx_train=existing_drug_idx, idx_test=target_idx, c=c, g=g)\n",
    "\n",
    "\n",
    "    # Set the out put of GNMF as prediction score\n",
    "    score = side_effects_drug_relation_fact.copy()\n",
    "\n",
    "    # Random score\n",
    "    random_score = np.random.rand(m,n)\n",
    "    \n",
    "\n",
    "    pr_auc_all = 0\n",
    "    roc_auc_all = 0\n",
    "    \n",
    "\n",
    "    prec, recall, threshold = precision_recall_curve(Ground_Truth[:, target_idx].ravel(), score[:, target_idx].ravel())\n",
    "    pr_auc_all = auc(recall, prec)\n",
    "    roc_auc_all = roc_auc_score(Ground_Truth[:, target_idx].ravel(), score[:, target_idx].ravel())\n",
    "\n",
    "\n",
    "    return pr_auc_all, roc_auc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotfold(IDX1,IDX2,feature_matrix1,feature_matrix2,matrix,c,g):\n",
    "    # IDX1 target index, need to be evaluated\n",
    "    # IDX2 test index, masked\n",
    "\n",
    "    target_idx = IDX1\n",
    "    mask_idx = IDX2\n",
    "    Ground_Truth = matrix.copy()\n",
    "    side_effects_drug_relation_copy = matrix.copy()\n",
    " \n",
    "    for i in range(len(mask_idx)):\n",
    "        side_effects_drug_relation_copy[:, mask_idx[i]] = 0\n",
    "    \n",
    "    m,n = side_effects_drug_relation_copy.shape\n",
    "\n",
    "    drug_idx = list(range(n))\n",
    "    existing_drug_idx = np.setdiff1d(drug_idx, mask_idx)\n",
    "    \n",
    "    # calculate the mean for each drug\n",
    "    mean_side_effect_score = (Ground_Truth.copy()[:, existing_drug_idx]).mean(axis=1)\n",
    "    score_mean = side_effects_drug_relation_copy.copy().astype(float)\n",
    "\n",
    "    # Set the prediction into mean\n",
    "    for i in range(m):\n",
    "        score_mean[i, mask_idx] =  mean_side_effect_score[i]\n",
    "\n",
    "    print(methodOption + ' starts:')\n",
    "    side_effects_drug_relation_fact = SVMforAllSe(matrix=matrix, feature_matrix1=feature_matrix1, feature_matrix2=feature_matrix2, idx_train=existing_drug_idx, idx_test=target_idx, c=c, g=g)\n",
    "    # sys.stdout = real_stdout\n",
    "    print(methodOption + ' ends:')\n",
    "\n",
    "\n",
    "    # Set the out put of GNMF as prediction score\n",
    "    score = side_effects_drug_relation_fact.copy()\n",
    "    # score = score_mean.copy()\n",
    "\n",
    "    \n",
    "    pr_auc_all = 0\n",
    "    roc_auc_all = 0\n",
    "    \n",
    "\n",
    "    print(\"proportion of ground truth:\", sum(Ground_Truth[:, target_idx].ravel())/(Ground_Truth[:, target_idx].shape[0]*Ground_Truth[:, target_idx].shape[1]))\n",
    "\n",
    "    print('---evaluation---')\n",
    "\n",
    "    prec, recall, prthreshold = precision_recall_curve(Ground_Truth[:, target_idx].ravel(), score[:, target_idx].ravel())\n",
    "    pr_auc_all = auc(recall, prec)\n",
    "    \n",
    "    fpr, tpr, rocthreshold = metrics.roc_curve(Ground_Truth[:, target_idx].ravel(), score[:, target_idx].ravel())\n",
    "    roc_auc_all = auc(fpr, tpr)\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "    print(\"AUC-PR all:\", pr_auc_all)\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "    print(\"AUC-ROC all:\", roc_auc_all)\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "    Out1 = pd.DataFrame([prec, recall, prthreshold])\n",
    "    Out2 = pd.DataFrame([fpr, tpr, rocthreshold])\n",
    "    return Out1, Out2\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for assigning arguments of CV and nested CV, as well as finding the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setvar_tune(size):\n",
    "# set var for hyper pars tuning size is the hyper par size ALL_...\n",
    "\n",
    "    global ALL_AUCPR_all\n",
    "    global ALL_AUROC_all\n",
    "\n",
    "    ALL_AUCPR_all = np.zeros(size)\n",
    "    ALL_AUROC_all = np.zeros(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setvar_cv(FOLDS):\n",
    "# set var for cv \n",
    "\n",
    "    global AUC_roc_all\n",
    "    global AUC_pr_all\n",
    "\n",
    "    AUC_roc_all = np.zeros(FOLDS)\n",
    "    AUC_pr_all = np.zeros(FOLDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asgvar_tune(idx, results):\n",
    "    # assign var for cv from results\n",
    "    # f: size of hyper pars\n",
    "\n",
    "    ALL_AUCPR_all[idx] = results[0]\n",
    "    ALL_AUROC_all[idx] = results[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asgvar_cv(f, results):\n",
    "    # assign var for cv from results\n",
    "    # f: size of hyper pars\n",
    "\n",
    "    AUC_pr_all[f] = results[0]\n",
    "    AUC_roc_all[f] = results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_results(tuneVar):\n",
    "    idx = np.argmax(ALL_AUCPR_all)\n",
    "    Var = tuneVar[idx]\n",
    "    Value = ALL_AUCPR_all[idx]\n",
    "\n",
    "    print(\"best hyperpar: \", Var)\n",
    "    print(\"AUPRC per drug: \", Value)\n",
    "\n",
    "    return Var, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setvar_besttune(innerfolds):\n",
    "    global besttunevalue\n",
    "    global besttunevar\n",
    "    besttunevalue = np.zeros(innerfolds) # best metric value\n",
    "    besttunevar = np.zeros(innerfolds) # the value of best var\n",
    "    besttunevar = besttunevar.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asg_besttune(f, value, var):\n",
    "    besttunevalue[f] = value\n",
    "    besttunevar[f] = var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def besttune():\n",
    "    idx = np.argmax(besttunevalue)\n",
    "    value = besttunevalue[idx]\n",
    "    var = besttunevar[idx]\n",
    "    return value, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_results():\n",
    "\n",
    "    print(\"Mean AUC_pr_all\", AUC_pr_all.mean(),\" \", \"Standard Deviation:\", AUC_pr_all.std())\n",
    "    print(\"Mean AUC_roc_all\", AUC_roc_all.mean(),\" \", \"Standard Deviation:\", AUC_roc_all.std())\n",
    "    print(\"-----------\")\n",
    "    results = np.array([AUC_pr_all, AUC_roc_all])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for parallel computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_loop(innermatrix, idx_train_inner, idx_test_inner, feature_matrix_inner1, feature_matrix_inner2, hyperparList, i):\n",
    "    \n",
    "    c,g = hyperparList[i]\n",
    "    idx_target_inner = idx_test_inner\n",
    "    results = innerfold(idx_target_inner,idx_test_inner,feature_matrix1=feature_matrix_inner1,feature_matrix2=feature_matrix_inner2,matrix=innermatrix,c=c,g=g)\n",
    "    asgvar_tune(i, results=results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(method_option,normalization=True,Validation=\"nested_cv\",sets=\"intersect\", c=0, g=0):\n",
    "\n",
    "    random.seed(1949) # for dataset split\n",
    "    np.random.seed(1949) # for matrix initialization\n",
    "    option(method_option)\n",
    "    option2(normalization)\n",
    "\n",
    "    random.seed(1949) # for dataset split\n",
    "    np.random.seed(1949) # for matrix initialization\n",
    "    df = pd.read_csv(\"data/side-effect-and-drug_name_upper.tsv\",sep = \"\\t\")\n",
    "    drug_id = df[\"drugbank_id\"] # put col of df in var\n",
    "    drug_name = df[\"drugbank_name\"]\n",
    "    side_effect = df[\"side_effect_name\"]\n",
    "    \n",
    "    \n",
    "    edgelist1 = zip(side_effect, drug_name)\n",
    "    ##making Biparite Graph##\n",
    "    B = nx.DiGraph()\n",
    "    B.add_nodes_from(side_effect,bipartite = 0)\n",
    "    B.add_nodes_from(drug_name,bipartite = 1)\n",
    "    B.add_edges_from(edgelist1)\n",
    "    # B.add_weighted_edges_from(edgelist2)\n",
    "    drug_nodes = {n for n, d in B.nodes(data=True) if d['bipartite']==1}\n",
    "    side_effect_nodes = {n for n, d in B.nodes(data=True) if d['bipartite']==0}\n",
    "    drug_nodes = list(drug_nodes)\n",
    "    drug_nodes.sort()\n",
    "    side_effect_nodes = list(side_effect_nodes)\n",
    "    side_effect_nodes.sort()\n",
    "    ###Getting the Bi-Adjacency matrix between side effects and drugs ###################\n",
    "    matrix_all = biadjacency_matrix(B, row_order = side_effect_nodes, column_order = drug_nodes) # create biadjacency matrix for drug side effect graph\n",
    "    matrix_all = matrix_all.A\n",
    "    m_all,n_all = matrix_all.shape # number of side effect # number of drug\n",
    "    \n",
    "    \n",
    "    ### Setting validation set / training set / testing set ###\n",
    "    validate_sz = int(0.25 * n_all)\n",
    "    IDX_all = list(range(n_all))\n",
    "    random.shuffle(IDX_all)\n",
    "    IDX_validate = sorted(IDX_all[0:validate_sz])\n",
    "    print(\"first few validation set idx:\")\n",
    "    print(IDX_validate[0:10])\n",
    "    IDX_validate_diff = np.setdiff1d(IDX_all, IDX_validate)\n",
    "    matrix = matrix_all[:, IDX_validate_diff].copy()\n",
    "    \n",
    "    df1 = pd.read_csv(\"data/intersection_DGIdb_mat.tsv\",sep = \"\\t\")\n",
    "    df2 = pd.read_csv(\"data/intersection_Fingerprint_mat.tsv\",sep = \"\\t\")\n",
    "    featureMat1_all = FeaturePreprocess(df1, drug_nodes=drug_nodes)\n",
    "    featureMat2_all = FeaturePreprocess(df2, drug_nodes=drug_nodes)\n",
    "    featureMat1 = featureMat1_all[IDX_validate_diff, :].copy()\n",
    "    featureMat2 = featureMat2_all[IDX_validate_diff, :].copy()\n",
    "    \n",
    "    \n",
    "    non_zero_idx_union = np.hstack(np.where(~((featureMat1.sum(1) == 0) & (featureMat2.sum(1) == 0))))\n",
    "    non_zero_idx_missing = np.hstack(np.where(~(~(featureMat1.sum(1) == 0) & ~(featureMat2.sum(1) == 0))))\n",
    "    non_zero_idx_intersect = np.hstack(np.where(~(featureMat1.sum(1) == 0) & ~(featureMat2.sum(1) == 0)))\n",
    "    if sets == \"union\":\n",
    "        # union\n",
    "        matrix = matrix[:, non_zero_idx_union].copy()\n",
    "        featureMat1 = featureMat1[non_zero_idx_union, :].copy()\n",
    "        featureMat2 = featureMat2[non_zero_idx_union, :].copy()\n",
    "    elif sets == \"intersect\":\n",
    "        # intersect\n",
    "        non_zero_idx_intersect_all = np.hstack(np.where(~(featureMat1_all.sum(1) == 0) & ~(featureMat2_all.sum(1) == 0)))\n",
    "    \n",
    "        matrix_all = matrix_all[:, non_zero_idx_intersect_all].copy()\n",
    "        featureMat1_all = featureMat1_all[non_zero_idx_intersect_all, :].copy()\n",
    "        featureMat2_all = featureMat2_all[non_zero_idx_intersect_all, :].copy()\n",
    "    \n",
    "        matrix = matrix[:, non_zero_idx_intersect].copy()\n",
    "        featureMat1 = featureMat1[non_zero_idx_intersect, :].copy()\n",
    "        featureMat2 = featureMat2[non_zero_idx_intersect, :].copy()\n",
    "    \n",
    "        IDX_validate = np.setdiff1d(non_zero_idx_intersect_all, IDX_validate_diff)\n",
    "        IDX_validate_diff = np.setdiff1d(non_zero_idx_intersect_all, IDX_validate)\n",
    "    \n",
    "        drug_nodes_intersect_all = np.array(drug_nodes)[non_zero_idx_intersect_all]\n",
    "        drug_nodes_intersect_validate_diff = np.array(drug_nodes)[IDX_validate_diff]\n",
    "        drug_nodes_intersect_validate = np.array(drug_nodes)[IDX_validate]\n",
    "    \n",
    "        IDX_validate = np.array([x for x in range(len(drug_nodes_intersect_all)) if drug_nodes_intersect_all[x] in drug_nodes_intersect_validate])\n",
    "        IDX_validate_diff = np.array([x for x in range(len(drug_nodes_intersect_all)) if drug_nodes_intersect_all[x] in drug_nodes_intersect_validate_diff])\n",
    "    \n",
    "\n",
    "    m,n = matrix.shape # number of side effect # number of drug\n",
    "\n",
    "\n",
    "    random.seed(1949) # for dataset split\n",
    "    np.random.seed(1949) # for matrix initialization\n",
    "\n",
    "\n",
    "\n",
    "    FOLDS = 5\n",
    "    innerFOLDS = 4\n",
    "    ####for test sets####\n",
    "    setvar_cv(FOLDS)\n",
    "\n",
    "    sz = n\n",
    "    IDX = list(range(sz))\n",
    "    fsz = int(sz/FOLDS)\n",
    "    random.shuffle(IDX)\n",
    "    IDX = np.array(IDX)\n",
    "    offset = 0\n",
    "\n",
    "    innersz = sz - fsz\n",
    "    innerIDX = list(range(innersz))\n",
    "    random.shuffle(innerIDX)\n",
    "    innerIDX = np.array(innerIDX)\n",
    "    innerfsz = int(innersz / innerFOLDS)\n",
    "    inneroffset = 0\n",
    "    # setvar_cv(FOLDS=FOLDS)\n",
    "\n",
    "    if Validation == \"nested_cv\":\n",
    "        print(\"---------- nested cv start ----------\")\n",
    "        for f in range(FOLDS):  # range(FOLDS):\n",
    "            offset = 0 + fsz*f \n",
    "            idx_test = IDX[offset:offset + fsz]\n",
    "    \n",
    "            idx_train = IDX[np.setdiff1d(np.arange(len(IDX)), np.arange(offset,offset + fsz))]\n",
    "            print(\"Fold:\",f)\n",
    "                \n",
    "            innermatrix = matrix[:, idx_train]\n",
    "    \n",
    "            innerfeatureMat1 = featureMat1[idx_train, :].copy()\n",
    "            innerfeatureMat2 = featureMat2[idx_train, :].copy()\n",
    "    \n",
    "            setvar_besttune(innerFOLDS)\n",
    "    \n",
    "            for innerf in range(innerFOLDS):\n",
    "                inneroffset = 0 + innerf*innerfsz\n",
    "                idx_test_inner = innerIDX[inneroffset:inneroffset + innerfsz]\n",
    "                idx_train_inner = innerIDX[np.array(np.setdiff1d(np.arange(len(idx_train)), np.arange(inneroffset,inneroffset + innerfsz)))]\n",
    "    \n",
    "                print(\"Inner Fold:\", innerf)\n",
    "\n",
    "                if (methodOption == \"SVMRBF1\") | (methodOption == \"SVMRBF2\") |  (methodOption == \"SVMRBF1&2\"):\n",
    "                    gamma = (10**np.arange(-4, -1, 1, dtype=float)).tolist()\n",
    "                elif (methodOption == \"SVML1\") | (methodOption == \"SVML2\") |  (methodOption == \"SVML1&2\"):\n",
    "                    gamma = (10**np.arange(1, 2, 1, dtype=float)).tolist()\n",
    "                C = (10**np.arange(-3, -2, 1, dtype=float)).tolist()\n",
    "                hyperparList = list(product(C, gamma))\n",
    "    \n",
    "                setvar_tune(len(hyperparList))\n",
    "    \n",
    "                with parallel_backend('threading'):\n",
    "                    Parallel(n_jobs=1)(delayed(tuning_loop)(innermatrix = innermatrix, idx_train_inner = idx_train_inner, \\\n",
    "                            idx_test_inner = idx_test_inner, feature_matrix_inner1 = innerfeatureMat1, feature_matrix_inner2 = innerfeatureMat2, \\\n",
    "                                hyperparList = hyperparList, i = i) \\\n",
    "                                    for i in range(len(hyperparList)))\n",
    "    \n",
    "                # tuning_plot(tuneVar=C, tune=\"C\")\n",
    "                hyperpars, evalValue = tuning_results(tuneVar=hyperparList)\n",
    "    \n",
    "    \n",
    "    \n",
    "                asg_besttune(innerf, value=evalValue, var=hyperpars)\n",
    "                    \n",
    "            _, bestHyperPars = besttune()\n",
    "    \n",
    "            print(\"--- tuning end ---\")\n",
    "            c, g = bestHyperPars\n",
    "            idx_target = idx_test\n",
    "            print('target size:', len(idx_target))\n",
    "    \n",
    "            print(\"------ C: \", c, \"gamma: \", g, \"------\")\n",
    "    \n",
    "            results = fold(idx_target,idx_test,featureMat1,featureMat2,matrix,c=c,g=g)\n",
    "            asgvar_cv(f=f, results=results)\n",
    "\n",
    "        out = cv_results()\n",
    "        return out\n",
    "\n",
    "    elif Validation == \"cv\":\n",
    "        print(\"---------- cv start ----------\")\n",
    "        setvar_besttune(FOLDS)\n",
    "\n",
    "        for f in range(FOLDS):\n",
    "            offset = 0 + fsz*f \n",
    "            idx_test = IDX[offset:offset + fsz]\n",
    "            idx_train = IDX[np.setdiff1d(np.arange(len(IDX)), np.arange(offset,offset + fsz))]\n",
    "\n",
    "            print(\"Fold:\", f)\n",
    "\n",
    "            if methodOption == \"SVMRBF1\" | methodOption == \"SVMRBF2\" |  methodOption == \"SVMRBF1&2\":\n",
    "                gamma = (10**np.arange(-4, -1, 1, dtype=float)).tolist()\n",
    "            elif methodOption == \"SVML1\" | methodOption == \"SVML2\" |  methodOption == \"SVML1&2\":\n",
    "                gamma = (10**np.arange(1, 2, 1, dtype=float)).tolist()\n",
    "            C = (10**np.arange(-1, -2, 1, dtype=float)).tolist()\n",
    "            hyperparList = list(product(C, gamma))\n",
    "\n",
    "            setvar_tune(len(hyperparList))\n",
    "    \n",
    "            with parallel_backend('threading'):\n",
    "                Parallel(n_jobs=1)(delayed(tuning_loop)(innermatrix = matrix, idx_train_inner = idx_train, \\\n",
    "                        idx_test_inner = idx_test, feature_matrix_inner1 = featureMat1, feature_matrix_inner2 = featureMat2, \\\n",
    "                            hyperparList = hyperparList, i = i) \\\n",
    "                                    for i in range(len(hyperparList)))\n",
    "    \n",
    "            hyperpars, evalValue = tuning_results(tuneVar=hyperparList)\n",
    "            asg_besttune(f, value=evalValue, var=hyperpars)\n",
    "\n",
    "    \n",
    "        print(\"--- tuning end ---\")\n",
    "        # cv_results()\n",
    "        _, bestHyperPars = besttune()\n",
    "    elif Validation == \"Validation\":\n",
    "\n",
    "        # validation\n",
    "        idx_test = IDX_validate\n",
    "        idx_train = IDX_validate_diff\n",
    "        idx_target = idx_test\n",
    "        print('target size:', len(idx_target))\n",
    "        print(\"------ C: \", c, \"gamma: \", g, \"------\")\n",
    "        results = fold(idx_target,idx_test,featureMat1_all,featureMat2_all,matrix_all,c=c,g=g)\n",
    "        return\n",
    "    elif Validation == \"plot\":\n",
    "        \n",
    "        # validation\n",
    "        idx_test = IDX_validate\n",
    "        idx_train = IDX_validate_diff\n",
    "        idx_target = idx_test\n",
    "        print('target size:', len(idx_target))\n",
    "        print(\"------ C: \", c, \"gamma: \", g, \"------\")\n",
    "        pr, roc = plotfold(idx_target,idx_test,featureMat1_all,featureMat2_all,matrix_all,c=c,g=g)\n",
    "        return pr, roc\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Nested CV and CV for SVM-linear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Nested CV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the nested CV for feature DGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_SVML_mean, results_SVML = main(method_option=\"SVML1\", Validation=\"nested_cv\") # C 0.001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the nested CV for feature Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_SVML_mean, results_SVML = main(method_option=\"SVML2\", Validation=\"nested_cv\") # C 0.001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the nested CV for feature DGI and Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_SVML_mean, results_SVML = main(method_option=\"SVML1&2\", Validation=\"nested_cv\") # C 0.001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. CV to tune hyperparameters for independent test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running CV for DGI. The best hyperparameter is $C=0.001$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option=\"SVML1\",Validation=\"cv\") # C 0.001"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running CV for Chem. The best hyperparameter is $C=0.001$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option=\"SVML2\",Validation=\"cv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running CV for DGI and Chem. The best hyperparameter is $C=0.001$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option=\"SVML1&2\",Validation=\"cv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Independent test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option=\"SVML1\", Validation=\"Validation\", c=0.001) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option=\"SVML2\", Validation=\"Validation\", c=0.001) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integration of DGI and Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option=\"SVML1&2\", Validation=\"Validation\", c=0.001) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Save data for PR and ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVML1_pr, SVML1_roc = \\\n",
    "    main(method_option=\"SVML1\", Validation=\"plot\", c=0.001)\n",
    "SVML1_pr.T.to_csv(\"Figs/SVML1_pr.csv\", index=False)\n",
    "SVML1_roc.T.to_csv(\"Figs/SVML1_roc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVML2_pr, SVML2_roc = \\\n",
    "    main(method_option=\"SVML2\", Validation=\"plot\", c=0.001)\n",
    "SVML2_pr.T.to_csv(\"Figs/SVML2_pr.csv\", index=False)\n",
    "SVML2_roc.T.to_csv(\"Figs/SVML2_roc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVML12_pr, SVML12_roc = \\\n",
    "    main(method_option=\"SVML1&2\", Validation=\"plot\", c=0.001)\n",
    "SVML12_pr.T.to_csv(\"Figs/SVML12_pr.csv\", index=False)\n",
    "SVML12_roc.T.to_csv(\"Figs/SVML12_roc.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('tf-2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac95e2fd4e3c95fb3fb1f7e38114c393d9f202cef380ef2efc5a4245619d104b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
