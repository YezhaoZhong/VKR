{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from networkx.algorithms.bipartite.matrix import biadjacency_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import time\n",
    "import numpy.linalg as LA\n",
    "from scipy.linalg import inv\n",
    "from joblib import Parallel, delayed\n",
    "from math import sqrt\n",
    "from sklearn.utils import parallel_backend\n",
    "from itertools import product\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "random.seed(1949) # for dataset split\n",
    "np.random.seed(1949) # for matrix initialization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is for the study of ADRs prediction using VKR. After the function in section 1 run, nested CV, CV and result of test set in section 2 can be ran separately."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the functions used for VKR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def option(str):\n",
    "    global methodOption\n",
    "    methodOption = str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for VKR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NMF(bipart_graph, component, WMK, lmd, max_iter, tolerance=1/1000000):\n",
    "    np.random.seed(1949)\n",
    "    random.seed(1949)\n",
    "\n",
    "    W = WMK.copy()\n",
    "    X = bipart_graph.copy()\n",
    "    m, n = X.shape\n",
    "    k = component\n",
    " \n",
    "    D = np.matrix(np.diag(np.asarray(W.copy()).sum(axis=1)))\n",
    "    L = D.copy() - W.copy()\n",
    "\n",
    "    # Initialize U & V\n",
    "\n",
    "    U = np.random.random((m, k))\n",
    "    V = np.random.random((n, k))\n",
    "\n",
    "    # Updating U V\n",
    "    eps = 2**-8\n",
    "\n",
    "    term1 = LA.norm(X - np.dot(U, V.T))**2\n",
    "    term2 = lmd * np.trace(np.dot(np.dot(V.T, L), V))\n",
    "    Obj0 = term1 + term2\n",
    "    Obj1 = Obj0\n",
    "\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        XV = np.dot(X, V)\n",
    "        UVtV = np.dot(np.dot(U, V.T), V) + eps\n",
    "\n",
    "        U *= XV\n",
    "        U /= UVtV\n",
    "        \n",
    "        XtU_lmdWV = np.dot(X.T, U) + lmd*np.dot(W, V)\n",
    "        VUtU_lmdDV = np.dot(np.dot(V, U.T), U) + lmd*np.dot(D, V) + eps\n",
    "        V *= XtU_lmdWV\n",
    "        V /= VUtU_lmdDV\n",
    "\n",
    "        # Objective function\n",
    "        \n",
    "        term1 = LA.norm(X - np.dot(U, V.T))**2\n",
    "        term2 = lmd * np.trace(np.dot(np.dot(V.T, L), V))\n",
    "        Obj2 = term1 + term2    \n",
    "        ObjDiff = Obj1 - Obj2\n",
    "        Obj1 = Obj2\n",
    "\n",
    "        if(ObjDiff < (Obj0 *tolerance)):\n",
    "            print(\"Converged in iteration: \", i, \"ObjDiff: \", ObjDiff, \"Obj: \", Obj2)\n",
    "            return(U, V, np.dot(U, V.T))\n",
    "        elif i == max_iter - 1:\n",
    "            print(\"Has not converged, reach the maximum iteration\")\n",
    "            return(U, V, np.dot(U, V.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KernelRegression(matrix,feature_matrix1,feature_matrix2,idx_train,idx_test,l1,l2,s):\n",
    "    sigma = s\n",
    "    lmd1 = l1\n",
    "    lmd2 = l2\n",
    "        \n",
    "    X1 = np.array(feature_matrix1[idx_train, :].copy()).tolist()\n",
    "    X_new1 = np.array(feature_matrix1[idx_test, :].copy()).tolist()\n",
    "    X2 = np.array(feature_matrix2[idx_train, :].copy()).tolist()\n",
    "    X_new2 = np.array(feature_matrix2[idx_test, :].copy()).tolist()\n",
    "    y = matrix[:, idx_train].copy()\n",
    "    Y = pd.DataFrame(y.T.copy())\n",
    "    matrix_new = matrix.copy().astype(float)\n",
    "\n",
    "    distance1 = cdist(X_new1, X1)**2\n",
    "    distance2 = cdist(X_new2, X2)**2\n",
    "\n",
    "    kernel1 = np.exp(-distance1/sigma**2)\n",
    "    kernel2 = np.exp(-distance2/sigma**2)\n",
    "\n",
    "    similarity1 = cdist(X1, X1)**2\n",
    "    similarity2 = cdist(X2, X2)**2\n",
    "\n",
    "    K1 = pd.DataFrame(np.exp(-similarity1/sigma**2))\n",
    "    K2 = pd.DataFrame(np.exp(-similarity2/sigma**2))\n",
    "\n",
    "    n = len(idx_train) # size of known drug\n",
    "\n",
    "    \n",
    "    if methodOption == \"KRNMF1\":\n",
    "        Lmd = np.diag(np.ones(n)*lmd1)\n",
    "        W = inv(K1.dot(K1)+Lmd).dot(K1.dot(Y))\n",
    "        y_new = kernel1.dot(W)\n",
    "    elif methodOption == \"KRNMF2\":\n",
    "        Lmd = np.diag(np.ones(n)*lmd1)\n",
    "        W = inv(K2.dot(K2)+Lmd).dot(K2.dot(Y))\n",
    "        y_new = kernel2.dot(W)\n",
    "    elif methodOption == \"KRNMF1&2\":\n",
    "        c1 = 0.5\n",
    "        c2 = 0.5\n",
    "        Lmd = np.diag(np.ones(n)*lmd1)\n",
    "        K = c1*K1 + c2*K2\n",
    "        W = inv(K.dot(K)+Lmd).dot(K.dot(Y))\n",
    "        y_new = (c1*kernel1+c2*kernel2).dot(W)\n",
    "\n",
    "    matrix_new[:, idx_test] = y_new.T\n",
    "    return matrix_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Adaptive(matrix,feature_matrix1,feature_matrix2,idx_train,idx_test,l1,l2,s,k):\n",
    "    sigma = s\n",
    "    lmd1 = l1\n",
    "    lmd2 = l2\n",
    "\n",
    "    X1 = np.array(feature_matrix1[idx_train, :].copy()).tolist()\n",
    "    X_new1 = np.array(feature_matrix1[idx_test, :].copy()).tolist()\n",
    "    X2 = np.array(feature_matrix2[idx_train, :].copy()).tolist()\n",
    "    X_new2 = np.array(feature_matrix2[idx_test, :].copy()).tolist()\n",
    "    y = matrix[:, idx_train].copy()\n",
    "    matrix_new = matrix.copy().astype(float)\n",
    "\n",
    "    similarity1 = cdist(X1, X1)**2\n",
    "    WMK1 = pd.DataFrame(np.exp(-similarity1/sigma**2))\n",
    "    similarity2 = cdist(X2, X2)**2\n",
    "    WMK2 = pd.DataFrame(np.exp(-similarity2/sigma**2))\n",
    "\n",
    "\n",
    "    m, n = matrix.shape\n",
    "    Vout = np.zeros((n, k))\n",
    "\n",
    "    if methodOption == \"KRNMF1\":\n",
    "        U,V,preds = NMF(y, component=k, WMK=WMK1, lmd=lmd2, max_iter=10000)\n",
    "        Vout[idx_train, :] = V\n",
    "    elif methodOption == \"KRNMF2\":\n",
    "        U,V,preds = NMF(y, component=k, WMK=WMK2, lmd=lmd2, max_iter=10000)\n",
    "        Vout[idx_train, :] = V\n",
    "    elif methodOption == \"KRNMF1&2\":\n",
    "        c1=0.5\n",
    "        c2=0.5\n",
    "        U,V,preds = NMF(y, component=k, WMK=c1*WMK1+c2*WMK2, lmd=lmd2, max_iter=10000)\n",
    "        Vout[idx_train, :] = V\n",
    "\n",
    "    Vpreds = KernelRegression(Vout.T,feature_matrix1,feature_matrix2,idx_train,idx_test,l1,l2,s)\n",
    "\n",
    "\n",
    "    preds = U.dot(Vpreds)\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for generating features for common drugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeaturePreprocess(df_all, drug_nodes):\n",
    "    \n",
    "    drug_nodes_df = np.intersect1d(df_all.index, drug_nodes)\n",
    "    df = df_all.loc[drug_nodes_df]\n",
    "    _, q = df.shape\n",
    "    drug_nodes_diff = np.setdiff1d(drug_nodes, (df.index).tolist())\n",
    "    n = len(drug_nodes_diff)\n",
    "    df_diff = pd.DataFrame(np.zeros(n*q).reshape(n,q))\n",
    "    df_diff.index = drug_nodes_diff\n",
    "    df_diff.columns = df.columns\n",
    "    df_all = pd.concat([df, df_diff], axis = 0)\n",
    "    featureMat = df_all.loc[drug_nodes]\n",
    "    return np.array(featureMat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for cross validation and nested cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold(IDX1,IDX2,feature_matrix1,feature_matrix2,matrix,l1,l2,s,k):\n",
    "    # IDX1 target index, need to be evaluated\n",
    "    # IDX2 test index, masked\n",
    "\n",
    "    target_idx = IDX1\n",
    "    mask_idx = IDX2\n",
    "    Ground_Truth = matrix.copy()\n",
    "    side_effects_drug_relation_copy = matrix.copy()\n",
    "\n",
    "    # target_idx = IDX2\n",
    "    ### making all the links to predict as 0 ###############    \n",
    "    for i in range(len(mask_idx)):\n",
    "        side_effects_drug_relation_copy[:, mask_idx[i]] = 0\n",
    "    \n",
    "    m,n = side_effects_drug_relation_copy.shape\n",
    "\n",
    "    drug_idx = list(range(n))\n",
    "    existing_drug_idx = np.setdiff1d(drug_idx, mask_idx)\n",
    "    \n",
    "    print(methodOption + ' starts:')\n",
    "    # real_stdout = sys.stdout\n",
    "    # sys.stdout = open(os.devnull, \"w\")\n",
    "    side_effects_drug_relation_fact = Adaptive(matrix=side_effects_drug_relation_copy,\\\n",
    "        feature_matrix1=feature_matrix1,feature_matrix2=feature_matrix2,idx_train=existing_drug_idx,idx_test=target_idx,l1=l1,l2=l2,s=s,k=k)\n",
    "    # sys.stdout = real_stdout\n",
    "    print(methodOption + ' ends:')\n",
    "\n",
    "\n",
    "    # Set the out put of GNMF as prediction score\n",
    "    score = side_effects_drug_relation_fact.copy()\n",
    "\n",
    "    pr_auc_all = 0\n",
    "    roc_auc_all = 0\n",
    "\n",
    "    print(\"proportion of ground truth:\", sum(Ground_Truth[:, target_idx].ravel())/(Ground_Truth[:, target_idx].shape[0]*Ground_Truth[:, target_idx].shape[1]))\n",
    "\n",
    "    print('---evaluation---')\n",
    "\n",
    "\n",
    "    prec, recall, threshold = precision_recall_curve(Ground_Truth[:, target_idx].ravel(), score[:, target_idx].ravel())\n",
    "    pr_auc_all = auc(recall, prec)\n",
    "    roc_auc_all = roc_auc_score(Ground_Truth[:, target_idx].ravel(), score[:, target_idx].ravel())\n",
    "\n",
    "\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "    print(\"AUC-PR all:\", pr_auc_all)\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "    print(\"AUC-ROC all:\", roc_auc_all)\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "\n",
    "    return pr_auc_all, roc_auc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innerfold(IDX1,IDX2,feature_matrix1,feature_matrix2,matrix,l1,l2,s,k):\n",
    "    # IDX1 target index, need to be evaluated\n",
    "    # IDX2 test index, masked\n",
    "\n",
    "    target_idx = IDX1\n",
    "    mask_idx = IDX2\n",
    "    Ground_Truth = matrix.copy()\n",
    "    side_effects_drug_relation_copy = matrix.copy()\n",
    "    ### making all the links to predict as 0 ###############    \n",
    "    for i in range(len(mask_idx)):\n",
    "        side_effects_drug_relation_copy[:, mask_idx[i]] = 0\n",
    "    \n",
    "    m,n = side_effects_drug_relation_copy.shape\n",
    "\n",
    "    drug_idx = list(range(n))\n",
    "    existing_drug_idx = np.setdiff1d(drug_idx, mask_idx)\n",
    "    \n",
    "    side_effects_drug_relation_fact = Adaptive(matrix=side_effects_drug_relation_copy,\\\n",
    "        feature_matrix1=feature_matrix1,feature_matrix2=feature_matrix2,idx_train=existing_drug_idx, idx_test=target_idx,l1=l1,l2=l2,s=s,k=k)\n",
    "\n",
    "    score = side_effects_drug_relation_fact.copy()\n",
    "\n",
    "    pr_auc_all = 0\n",
    "    roc_auc_all = 0\n",
    "    \n",
    "    prec, recall, threshold = precision_recall_curve(Ground_Truth[:, target_idx].ravel(), score[:, target_idx].ravel())\n",
    "    pr_auc_all = auc(recall, prec)\n",
    "\n",
    "    return pr_auc_all, roc_auc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotfold(IDX1,IDX2,feature_matrix1,feature_matrix2,matrix,l1,l2,s,k):\n",
    "    # IDX1 target index, need to be evaluated\n",
    "    # IDX2 test index, masked\n",
    "\n",
    "    print('First few target index:', IDX1[0:10])\n",
    "    print('First few mask index:', IDX2[0:10])\n",
    "\n",
    "    target_idx = IDX1\n",
    "    mask_idx = IDX2\n",
    "    Ground_Truth = matrix.copy()\n",
    "    side_effects_drug_relation_copy = matrix.copy()\n",
    "    ### making all the links to predict as 0 ###############    \n",
    "    for i in range(len(mask_idx)):\n",
    "        side_effects_drug_relation_copy[:, mask_idx[i]] = 0\n",
    "    \n",
    "    m,n = side_effects_drug_relation_copy.shape\n",
    "\n",
    "    drug_idx = list(range(n))\n",
    "    existing_drug_idx = np.setdiff1d(drug_idx, mask_idx)\n",
    "    \n",
    "    print(methodOption + ' starts:')\n",
    "    side_effects_drug_relation_fact = Adaptive(matrix=side_effects_drug_relation_copy,\\\n",
    "        feature_matrix1=feature_matrix1,feature_matrix2=feature_matrix2,idx_train=existing_drug_idx,idx_test=target_idx,l1=l1,l2=l2,s=s,k=k)\n",
    "    print(methodOption + ' ends:')\n",
    "\n",
    "\n",
    "    score = side_effects_drug_relation_fact.copy()\n",
    "\n",
    "\n",
    "    print(\"proportion of ground truth:\", sum(Ground_Truth[:, target_idx].ravel())/(Ground_Truth[:, target_idx].shape[0]*Ground_Truth[:, target_idx].shape[1]))\n",
    "\n",
    "    print('---evaluation---')\n",
    "\n",
    "\n",
    "    prec, recall, prthreshold = precision_recall_curve(Ground_Truth[:, target_idx].ravel(), score[:, target_idx].ravel())\n",
    "    pr_auc_all = auc(recall, prec)\n",
    "    fpr, tpr, rocthreshold = metrics.roc_curve(Ground_Truth[:, target_idx].ravel(), score[:, target_idx].ravel())\n",
    "    roc_auc_all = auc(fpr, tpr)\n",
    "\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "    print(\"AUC-PR all:\", pr_auc_all)\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "    print(\"AUC-ROC all:\", roc_auc_all)\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "    Out1 = pd.DataFrame([prec, recall, prthreshold])\n",
    "    Out2 = pd.DataFrame([fpr, tpr, rocthreshold])\n",
    "    return Out1, Out2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for assigning arguments of CV and nested CV, as well as finding the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setvar_tune(size):\n",
    "    # set var for hyper pars tuning size is the hyper par size ALL_...\n",
    "\n",
    "    global ALL_AUCPR_all\n",
    "    global ALL_AUROC_all\n",
    "\n",
    "    ALL_AUCPR_all = np.zeros(size)\n",
    "    ALL_AUROC_all = np.zeros(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setvar_cv(FOLDS):\n",
    "    # set var for cv \n",
    "\n",
    "    global AUC_roc_all\n",
    "    global AUC_pr_all\n",
    "    \n",
    "    AUC_roc_all = np.zeros(FOLDS)\n",
    "    AUC_pr_all = np.zeros(FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asgvar_tune(idx, results):\n",
    "    # assign var for cv from results\n",
    "    # f: size of hyper pars\n",
    "\n",
    "    ALL_AUCPR_all[idx] = results[0]\n",
    "    ALL_AUROC_all[idx] = results[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asgvar_cv(f, results):\n",
    "    # assign var for cv from results\n",
    "    # f: size of hyper pars\n",
    "\n",
    "    AUC_pr_all[f] = results[0]\n",
    "    AUC_roc_all[f] = results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_results(tuneVar):\n",
    "    idx = np.argmax(ALL_AUCPR_all)\n",
    "    Var = tuneVar[idx]\n",
    "    Value = ALL_AUCPR_all[idx]\n",
    "\n",
    "    print(\"best hyperpar: \", Var)\n",
    "    print(\"AUPRC: \", Value)\n",
    "\n",
    "    \n",
    "    return Var, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setvar_besttune(innerfolds):\n",
    "    global besttunevalue\n",
    "    global besttunevar\n",
    "    besttunevalue = np.zeros(innerfolds) # best metric value\n",
    "    besttunevar = np.zeros(innerfolds) # the value of best var\n",
    "    besttunevar = besttunevar.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asg_besttune(f, value, var):\n",
    "    besttunevalue[f] = value\n",
    "    besttunevar[f] = var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def besttune():\n",
    "    idx = np.argmax(besttunevalue)\n",
    "    value = besttunevalue[idx]\n",
    "    var = besttunevar[idx]\n",
    "    return value, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_results():\n",
    "    \n",
    "    print(\"Mean AUC_pr_all\", AUC_pr_all.mean(),\" \", \"Standard Deviation:\", AUC_pr_all.std())\n",
    "    print(\"Mean AUC_roc_all\", AUC_roc_all.mean(),\" \", \"Standard Deviation:\", AUC_roc_all.std())\n",
    "    print(\"-----------\")\n",
    "    results = np.array([AUC_pr_all, AUC_roc_all])\n",
    "\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for parallel computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_loop(innermatrix, idx_train_inner, idx_test_inner, feature_matrix_inner1, feature_matrix_inner2, hyperparList, i):\n",
    "    \n",
    "    l1,l2,s,k = hyperparList[i]\n",
    "    idx_target_inner = idx_test_inner\n",
    "    # print('target size:', len(idx_target_inner))\n",
    "    results = innerfold(idx_target_inner,idx_test_inner,feature_matrix1=feature_matrix_inner1,feature_matrix2=feature_matrix_inner2,matrix=innermatrix,l1=l1,l2=l2,s=s,k=k)\n",
    "    asgvar_tune(i, results=results)\n",
    "    # print(\"------ lmdKR: \", l1, \"lmdNMF: \", l2, \"sigma: \", s, \"k: \", k, \"------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(method_option,normalization=True,Validation=False,sets=\"intersect\", l1=0.5, l2=0, s=0.5, k=20):\n",
    "    random.seed(1949) # for dataset split\n",
    "    np.random.seed(1949) # for matrix initialization\n",
    "    option(method_option)\n",
    "\n",
    "    random.seed(1949) # for dataset split\n",
    "    np.random.seed(1949) # for matrix initialization\n",
    "    df = pd.read_csv(\"data/side-effect-and-drug_name_upper.tsv\",sep = \"\\t\")\n",
    "    drug_id = df[\"drugbank_id\"] # put col of df in var\n",
    "    drug_name = df[\"drugbank_name\"]\n",
    "    side_effect = df[\"side_effect_name\"]\n",
    "    \n",
    "    \n",
    "    edgelist1 = zip(side_effect, drug_name)\n",
    "    ##making Biparite Graph##\n",
    "    B = nx.DiGraph()\n",
    "    B.add_nodes_from(side_effect,bipartite = 0)\n",
    "    B.add_nodes_from(drug_name,bipartite = 1)\n",
    "    B.add_edges_from(edgelist1)\n",
    "    # B.add_weighted_edges_from(edgelist2)\n",
    "    drug_nodes = {n for n, d in B.nodes(data=True) if d['bipartite']==1}\n",
    "    side_effect_nodes = {n for n, d in B.nodes(data=True) if d['bipartite']==0}\n",
    "    drug_nodes = list(drug_nodes)\n",
    "    drug_nodes.sort()\n",
    "    side_effect_nodes = list(side_effect_nodes)\n",
    "    side_effect_nodes.sort()\n",
    "    ###Getting the Bi-Adjacency matrix between side effects and drugs ###################\n",
    "    matrix_all = biadjacency_matrix(B, row_order = side_effect_nodes, column_order = drug_nodes) # create biadjacency matrix for drug side effect graph\n",
    "    matrix_all = matrix_all.A\n",
    "    m_all,n_all = matrix_all.shape # number of side effect # number of drug\n",
    "    \n",
    "    \n",
    "    ### Setting validation set / training set / testing set ###\n",
    "    validate_sz = int(0.25 * n_all)\n",
    "    IDX_all = list(range(n_all))\n",
    "    random.shuffle(IDX_all)\n",
    "    IDX_validate = sorted(IDX_all[0:validate_sz])\n",
    "    print(\"first few validation set idx:\")\n",
    "    print(IDX_validate[0:10])\n",
    "    IDX_validate_diff = np.setdiff1d(IDX_all, IDX_validate)\n",
    "    matrix = matrix_all[:, IDX_validate_diff].copy()\n",
    "    # featureMat1 = featureMat1_all[IDX_validate_diff, :][:, IDX_validate_diff].copy()\n",
    "    # featureMat2 = featureMat2_all[IDX_validate_diff, :][:, IDX_validate_diff].copy()\n",
    "    # print(\"WMK shape:\")\n",
    "    # print(featureMat1.shape)\n",
    "    \n",
    "    df1 = pd.read_csv(\"data/intersection_DGIdb_mat.tsv\",sep = \"\\t\")\n",
    "    df2 = pd.read_csv(\"data/intersection_Fingerprint_mat.tsv\",sep = \"\\t\")\n",
    "    featureMat1_all = FeaturePreprocess(df1, drug_nodes=drug_nodes)\n",
    "    featureMat2_all = FeaturePreprocess(df2, drug_nodes=drug_nodes)\n",
    "    # drug_nodes_feature1 = featureMat1_all.index\n",
    "    # drug_nodes_feature2 = featureMat2_all.index\n",
    "    featureMat1 = featureMat1_all[IDX_validate_diff, :].copy()\n",
    "    featureMat2 = featureMat2_all[IDX_validate_diff, :].copy()\n",
    "    \n",
    "    \n",
    "    non_zero_idx_union = np.hstack(np.where(~((featureMat1.sum(1) == 0) & (featureMat2.sum(1) == 0))))\n",
    "    non_zero_idx_missing = np.hstack(np.where(~(~(featureMat1.sum(1) == 0) & ~(featureMat2.sum(1) == 0))))\n",
    "    non_zero_idx_intersect = np.hstack(np.where(~(featureMat1.sum(1) == 0) & ~(featureMat2.sum(1) == 0)))\n",
    "    if sets == \"union\":\n",
    "        # union\n",
    "        matrix = matrix[:, non_zero_idx_union].copy()\n",
    "        featureMat1 = featureMat1[non_zero_idx_union, :].copy()\n",
    "        featureMat2 = featureMat2[non_zero_idx_union, :].copy()\n",
    "    elif sets == \"intersect\":\n",
    "        # intersect\n",
    "        non_zero_idx_intersect_all = np.hstack(np.where(~(featureMat1_all.sum(1) == 0) & ~(featureMat2_all.sum(1) == 0)))\n",
    "    \n",
    "        matrix_all = matrix_all[:, non_zero_idx_intersect_all].copy()\n",
    "        featureMat1_all = featureMat1_all[non_zero_idx_intersect_all, :].copy()\n",
    "        featureMat2_all = featureMat2_all[non_zero_idx_intersect_all, :].copy()\n",
    "    \n",
    "        matrix = matrix[:, non_zero_idx_intersect].copy()\n",
    "        featureMat1 = featureMat1[non_zero_idx_intersect, :].copy()\n",
    "        featureMat2 = featureMat2[non_zero_idx_intersect, :].copy()\n",
    "    \n",
    "        IDX_validate = np.setdiff1d(non_zero_idx_intersect_all, IDX_validate_diff)\n",
    "        IDX_validate_diff = np.setdiff1d(non_zero_idx_intersect_all, IDX_validate)\n",
    "    \n",
    "        drug_nodes_intersect_all = np.array(drug_nodes)[non_zero_idx_intersect_all]\n",
    "        drug_nodes_intersect_validate_diff = np.array(drug_nodes)[IDX_validate_diff]\n",
    "        drug_nodes_intersect_validate = np.array(drug_nodes)[IDX_validate]\n",
    "    \n",
    "        IDX_validate = np.array([x for x in range(len(drug_nodes_intersect_all)) if drug_nodes_intersect_all[x] in drug_nodes_intersect_validate])\n",
    "        IDX_validate_diff = np.array([x for x in range(len(drug_nodes_intersect_all)) if drug_nodes_intersect_all[x] in drug_nodes_intersect_validate_diff])\n",
    "    \n",
    "    m,n = matrix.shape # number of side effect # number of drug\n",
    "\n",
    "\n",
    "    random.seed(1949) # for dataset split\n",
    "    np.random.seed(1949) # for matrix initialization\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    FOLDS = 5\n",
    "    innerFOLDS = 4\n",
    "    ####for test sets####\n",
    "    setvar_cv(FOLDS)\n",
    "\n",
    "    sz = n\n",
    "    IDX = list(range(sz))\n",
    "    fsz = int(sz/FOLDS)\n",
    "    random.shuffle(IDX)\n",
    "    IDX = np.array(IDX)\n",
    "    offset = 0\n",
    "\n",
    "    innersz = sz - fsz\n",
    "    innerIDX = list(range(innersz))\n",
    "    random.shuffle(innerIDX)\n",
    "    innerIDX = np.array(innerIDX)\n",
    "    innerfsz = int(innersz / innerFOLDS)\n",
    "    inneroffset = 0\n",
    "    # setvar_cv(FOLDS=FOLDS)\n",
    "\n",
    "    if Validation == \"nested_cv\":\n",
    "        print(\"---------- nested cv start ----------\")\n",
    "        for f in range(FOLDS):  # range(FOLDS):\n",
    "            offset = 0 + fsz*f \n",
    "            idx_test = IDX[offset:offset + fsz]\n",
    "    \n",
    "            idx_train = IDX[np.setdiff1d(np.arange(len(IDX)), np.arange(offset,offset + fsz))]\n",
    "            print(\"Fold:\",f)\n",
    "                \n",
    "            innermatrix = matrix[:, idx_train]\n",
    "    \n",
    "            innerfeatureMat1 = featureMat1[idx_train, :].copy()\n",
    "            innerfeatureMat2 = featureMat2[idx_train, :].copy()\n",
    "    \n",
    "            setvar_besttune(innerFOLDS)\n",
    "    \n",
    "            for innerf in range(innerFOLDS):\n",
    "                inneroffset = 0 + innerf*innerfsz\n",
    "                idx_test_inner = innerIDX[inneroffset:inneroffset + innerfsz]\n",
    "                idx_train_inner = innerIDX[np.array(np.setdiff1d(np.arange(len(idx_train)), np.arange(inneroffset,inneroffset + innerfsz)))]\n",
    "    \n",
    "                print(\"Inner Fold:\", innerf)\n",
    "\n",
    "\n",
    "                \n",
    "                if method_option == \"KRNMF1\":\n",
    "                    lmd1 = (10**np.arange(-3, 1, 1, dtype=float)).tolist()\n",
    "                    lmd2 = (np.arange(0, 1, 1, dtype=float)).tolist()\n",
    "                    sigma = (10**np.arange(0, 3, 1, dtype=float)).tolist()\n",
    "                    comp = np.arange(5, 25, 5, dtype=int).tolist()\n",
    "                elif method_option == \"KRNMF2\":\n",
    "                    lmd1 = (10**np.arange(-4, 2, 1, dtype=float)).tolist()\n",
    "                    lmd2 = (np.arange(0, 1, 1, dtype=float)).tolist()\n",
    "                    sigma = (10**np.arange(0, 5, 1, dtype=float)).tolist()\n",
    "                    comp = np.arange(5, 30, 5, dtype=int).tolist()\n",
    "                if method_option == \"KRNMF1&2\":\n",
    "                    lmd1 = (10**np.arange(-3, 1, 1, dtype=float)).tolist()\n",
    "                    lmd2 = (np.arange(0, 1, 1, dtype=float)).tolist()\n",
    "                    sigma = (10**np.arange(0, 3, 1, dtype=float)).tolist()\n",
    "                    comp = np.arange(10, 45, 5, dtype=int).tolist()\n",
    "                    \n",
    "                hyperparList = list(product(lmd1, lmd2, sigma, comp))\n",
    "\n",
    "    \n",
    "                setvar_tune(len(hyperparList))\n",
    "    \n",
    "                with parallel_backend('threading'):\n",
    "                    Parallel(n_jobs=5)(delayed(tuning_loop)(innermatrix = innermatrix, idx_train_inner = idx_train_inner, \\\n",
    "                            idx_test_inner = idx_test_inner, feature_matrix_inner1 = innerfeatureMat1, feature_matrix_inner2 = innerfeatureMat2, \\\n",
    "                                hyperparList = hyperparList, i = i) \\\n",
    "                                    for i in range(len(hyperparList)))\n",
    "    \n",
    "                # tuning_plot(tuneVar=C, tune=\"C\")\n",
    "                hyperpars, evalValue = tuning_results(tuneVar=hyperparList)\n",
    "    \n",
    "    \n",
    "                asg_besttune(innerf, value=evalValue, var=hyperpars)\n",
    "                    \n",
    "            _, bestHyperPars = besttune()\n",
    "    \n",
    "            print(\"--- tuning end ---\")\n",
    "            l1, l2, s, k = bestHyperPars\n",
    "            idx_target = idx_test\n",
    "            print('target size:', len(idx_target))\n",
    "    \n",
    "            print(\"------ lmdKR: \", l1, \"lmdGNMF: \", l2, \"sigma: \", s, \"k: \", k, \"------\")\n",
    "    \n",
    "            results = fold(idx_target,idx_test,featureMat1,featureMat2,matrix,l1=l1,l2=l2,s=s,k=k)\n",
    "            asgvar_cv(f=f, results=results)\n",
    "\n",
    "        out_mean, out = cv_results()\n",
    "        return out_mean, out\n",
    "\n",
    "    elif Validation == \"cv\":\n",
    "        print(\"---------- cv start ----------\")\n",
    "        setvar_besttune(FOLDS)\n",
    "\n",
    "        for f in range(FOLDS):\n",
    "            offset = 0 + fsz*f \n",
    "            idx_test = IDX[offset:offset + fsz]\n",
    "            idx_train = IDX[np.setdiff1d(np.arange(len(IDX)), np.arange(offset,offset + fsz))]\n",
    "\n",
    "            print(\"Fold:\", f)\n",
    "            if method_option == \"KRNMF1\":\n",
    "                lmd1 = (10**np.arange(-3, 1, 1, dtype=float)).tolist()\n",
    "                lmd2 = (np.arange(0, 1, 1, dtype=float)).tolist()\n",
    "                sigma = (10**np.arange(0, 3, 1, dtype=float)).tolist()\n",
    "                comp = np.arange(5, 40, 5, dtype=int).tolist()\n",
    "            elif method_option == \"KRNMF2\":\n",
    "                lmd1 = (10**np.arange(-3, 2, 1, dtype=float)).tolist()\n",
    "                lmd2 = (np.arange(0, 1, 1, dtype=float)).tolist()\n",
    "                sigma = (10**np.arange(0, 4, 1, dtype=float)).tolist()\n",
    "                comp = np.arange(5, 30, 5, dtype=int).tolist()\n",
    "            if method_option == \"KRNMF1&2\":\n",
    "                lmd1 = (10**np.arange(-3, 2, 1, dtype=float)).tolist()\n",
    "                lmd2 = (np.arange(0, 1, 1, dtype=float)).tolist()\n",
    "                sigma = (10**np.arange(0, 3, 1, dtype=float)).tolist()\n",
    "                comp = np.arange(5, 40, 5, dtype=int).tolist()\n",
    "            hyperparList = list(product(lmd1, lmd2, sigma, comp))\n",
    "\n",
    "            setvar_tune(len(hyperparList))\n",
    "    \n",
    "            with parallel_backend('threading'):\n",
    "                Parallel(n_jobs=5)(delayed(tuning_loop)(innermatrix = matrix, idx_train_inner = idx_train, \\\n",
    "                        idx_test_inner = idx_test, feature_matrix_inner1 = featureMat1, feature_matrix_inner2 = featureMat2, \\\n",
    "                            hyperparList = hyperparList, i = i) \\\n",
    "                                for i in range(len(hyperparList)))\n",
    "    \n",
    "            hyperpars, evalValue = tuning_results(tuneVar=hyperparList)\n",
    "            asg_besttune(f, value=evalValue, var=hyperpars)\n",
    "\n",
    "        print(\"--- tuning end ---\")\n",
    "        # cv_results()\n",
    "        _, bestHyperPars = besttune()\n",
    "    elif Validation == \"Validation\":\n",
    "\n",
    "        # validation\n",
    "        idx_test = IDX_validate\n",
    "        idx_train = IDX_validate_diff\n",
    "        idx_target = idx_test\n",
    "        print('target size:', len(idx_target))\n",
    "        print(\"------ lmdKR: \", l1, \"lmdNMF: \", l2, \"sigma: \", s, \"k: \", k, \"------\")\n",
    "        results = fold(idx_target,idx_test,featureMat1_all,featureMat2_all,matrix_all,l1=l1,l2=l2,s=s,k=k)\n",
    "        return\n",
    "    elif Validation == \"plot\":\n",
    "\n",
    "        # validation\n",
    "        idx_test = IDX_validate\n",
    "        idx_train = IDX_validate_diff\n",
    "        idx_target = idx_test\n",
    "        print('target size:', len(idx_target))\n",
    "        print(\"------ lmdKR: \", l1, \"lmdNMF: \", l2, \"sigma: \", s, \"k: \", k, \"------\")\n",
    "        pr, roc = plotfold(idx_target,idx_test,featureMat1_all,featureMat2_all,matrix_all,l1=l1,l2=l2,s=s,k=k)\n",
    "        return pr, roc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Nested CV and CV for VKR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Nested CV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the nested CV for feature DGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_KRNMF1_mean, results_KRNMF1 = main(method_option=\"KRNMF1\",Validation=\"nested_cv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the nested CV for feature Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_KRNMF2_mean, results_KRNMF2 = main(method_option=\"KRNMF2\",Validation=\"nested_cv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the nested CV for integrated features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_KRNMF1_2_mean, results_KRNMF1_2 = main(method_option=\"KRNMF1&2\",Validation=\"nested_cv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. CV to tune hyperparameters for independent test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running CV for DGI. The best hyperparameters are $\\lambda=0.01, \\sigma=10, k=20$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option=\"KRNMF1\",Validation=\"cv\") # 0.01 10 20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running CV for Chem. The best hyperparameters are $\\lambda=0.1, \\sigma=10, k=20$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option=\"KRNMF2\",Validation=\"cv\") # 0.1 10 20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running CV for DGI and Chem. The best hyperparameters are $\\lambda=0.01, \\sigma=10, k=25$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option=\"KRNMF1&2\",Validation=\"cv\") # 0.01 10 25"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Independent test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option=\"KRNMF1\", Validation=\"Validation\", l1=0.01, l2=0, s=10, k=20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option=\"KRNMF2\", Validation=\"Validation\", l1=0.1, l2=0, s=10, k=20) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integration of DGI and Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option=\"KRNMF1&2\", Validation=\"Validation\", l1=0.01, l2=0, s=10, k=25) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Save data for PR and ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KRNMF1_pr, KRNMF1_roc = \\\n",
    "    main(method_option=\"KRNMF1\", Validation=\"plot\", l1=0.01, l2=0, s=10, k=20)          \n",
    "KRNMF1_pr.T.to_csv(\"Figs/KRNMF1_pr.csv\", index=False)\n",
    "KRNMF1_roc.T.to_csv(\"Figs/KRNMF1_roc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KRNMF2_pr, KRNMF2_roc = \\\n",
    "    main(method_option=\"KRNMF2\", Validation=\"plot\", l1=0.1, l2=0, s=10, k=20)\n",
    "KRNMF2_pr.T.to_csv(\"Figs/KRNMF2_pr.csv\", index=False)\n",
    "KRNMF2_roc.T.to_csv(\"Figs/KRNMF2_roc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KRNMF12_pr, KRNMF12_roc = \\\n",
    "    main(method_option=\"KRNMF1&2\", Validation=\"plot\", l1=0.01, l2=0, s=10, k=25)\n",
    "KRNMF12_pr.T.to_csv(\"Figs/KRNMF12_pr.csv\", index=False)\n",
    "KRNMF12_roc.T.to_csv(\"Figs/KRNMF12_roc.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (default, Jun  4 2021, 12:28:51) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac95e2fd4e3c95fb3fb1f7e38114c393d9f202cef380ef2efc5a4245619d104b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
