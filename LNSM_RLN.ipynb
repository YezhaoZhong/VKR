{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from networkx.algorithms.bipartite.matrix import biadjacency_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_recall_curve, auc\n",
    "import random\n",
    "from sklearn import metrics\n",
    "import time\n",
    "from joblib import Parallel, delayed\n",
    "from sklearn.utils import parallel_backend\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy.linalg as LA\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "random.seed(1949) # for dataset split\n",
    "np.random.seed(1949) # for matrix initialization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is for the study of ADRs prediction using LNSM, LNSM-CMI and LNSM-SMI with Regularized Linear Neighbourhood (RLN) similarity. After the function in section 1 run, nested CV, CV and result of test set in section 2 can be ran separately."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Define the functions used for LNSM-RLN family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def option(str):\n",
    "    global methodOption\n",
    "    methodOption = str"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for calculating regularized linear neightbourhood similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RLN(feature_matrix, idx_train, idx_test):\n",
    "    X = feature_matrix[idx_train, :]\n",
    "    X_new = feature_matrix[idx_test, :]\n",
    "\n",
    "    neigh = NearestNeighbors(n_neighbors = 200)\n",
    "    neigh.fit(X)\n",
    "    W = np.zeros([len(idx_train), len(idx_train)])\n",
    "    W_new = np.zeros([len(idx_test), len(idx_train)])\n",
    "    clf = Ridge(alpha=1)\n",
    "\n",
    "    N = neigh.kneighbors(X, 200, return_distance=False)\n",
    "    for i in range(len(idx_train)):\n",
    "        # print(\"test\")\n",
    "        X_knn = X[N[i], :]\n",
    "        clf.fit(X_knn.T, X[i, :])\n",
    "        W[i, N] = clf.coef_\n",
    "\n",
    "    N_new = neigh.kneighbors(X_new, 200, return_distance=False)\n",
    "    for i in range(len(idx_test)):\n",
    "        X_knn_new = X[N_new[i], :]\n",
    "        clf.fit(X_knn_new.T, X_new[i, :])\n",
    "        W_new[i, N_new[i]] = clf.coef_\n",
    "\n",
    "    return W, W_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LNSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LNSM(matrix, feature_matrix, alpha, idx_train, idx_test):\n",
    "    Y_0 = (matrix[:, idx_train].copy()).T\n",
    "\n",
    "    W, W_new = RLN(feature_matrix=feature_matrix, idx_train=idx_train, idx_test=idx_test)\n",
    "\n",
    "    max_iter = 1000\n",
    "    Y_t1 = Y_0.copy()\n",
    "    cost_t1 = alpha * np.trace(np.dot(np.dot(Y_t1.T, 1 - W), Y_t1)) + (1 - alpha)*LA.norm(Y_t1 - Y_0)**2\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        Y_t2 = alpha * np.dot(W, Y_t1) + (1 - alpha) * Y_0\n",
    "\n",
    "        cost_t2 = alpha * np.trace(np.dot(np.dot(Y_t2.T, 1 - W), Y_t2)) + (1 - alpha)*LA.norm(Y_t2 - Y_0)**2\n",
    "        # print(\"---\")\n",
    "        # print(alpha)\n",
    "        # print(cost_t2)\n",
    "        Y_t1 = Y_t2.copy()\n",
    "        cost_t1 = cost_t2\n",
    "\n",
    "        if (cost_t2 - cost_t1) < (cost_t1 / 10000):\n",
    "            print(\"LNSM converged\")\n",
    "            break\n",
    "        if i == (max_iter - 1):\n",
    "            print(\"maximum iteration reached\")\n",
    "\n",
    "    Y = Y_t2.copy()\n",
    "\n",
    "    \n",
    "    # Y = (1 - alpha) * np.dot(np.linalg.pinv(1 - alpha * W), Y_0)\n",
    "    Y_new = np.dot(W_new, Y)\n",
    "    matrix_new = matrix.copy().astype(float)\n",
    "    matrix_new[:, idx_test] = Y_new.T\n",
    "    # print(sum(sum(matrix_new[:, idx_test])))\n",
    "    return matrix_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LNSM-SMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LNSM_SMI(matrix, feature_matrix1, feature_matrix2, alpha, idx_train, idx_test):\n",
    "    Y_0 = (matrix[:, idx_train].copy()).T\n",
    "    \n",
    "    W1, W1_new = RLN(feature_matrix=feature_matrix1, idx_train=idx_train, idx_test=idx_test)    \n",
    "    W2, W2_new = RLN(feature_matrix=feature_matrix2, idx_train=idx_train, idx_test=idx_test)\n",
    "    \n",
    "\n",
    "\n",
    "    # Y = (1 - alpha) * np.linalg.inv(1 - alpha * W)\n",
    "    c1 = np.trace(np.dot(np.dot(Y_0.T, 1 - W1), Y_0))\n",
    "    c2 = np.trace(np.dot(np.dot(Y_0.T, 1 - W2), Y_0))\n",
    "    cmax = max(c1, c2)\n",
    "    theta1 = (cmax - c1) / ((cmax - c1) + (cmax - c2))\n",
    "    theta2 = (cmax - c2) / ((cmax - c1) + (cmax - c2))\n",
    "\n",
    "    Y_new = np.dot((np.dot(theta1, W1_new) + np.dot(theta2, W2_new)), Y_0)\n",
    "    matrix_new = matrix.copy().astype(float)\n",
    "    matrix_new[:, idx_test] = Y_new.T\n",
    "    # print(sum(sum(matrix_new[:, idx_test])))\n",
    "    return matrix_new"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LNSM-CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LNSM_CMI(matrix, feature_matrix1, feature_matrix2, alpha, idx_train, idx_test):\n",
    "    Y_0 = (matrix[:, idx_train].copy()).T\n",
    "    # W1 = WMK1[idx_train, :][:, idx_train].copy()\n",
    "    # W2 = WMK2[idx_train, :][:, idx_train].copy()\n",
    "    # W1_new = WMK1[idx_test, :][:, idx_train].copy()\n",
    "    # W2_new = WMK2[idx_test, :][:, idx_train].copy()\n",
    "    W1, W1_new = RLN(feature_matrix=feature_matrix1, idx_train=idx_train, idx_test=idx_test)    \n",
    "    W2, W2_new = RLN(feature_matrix=feature_matrix2, idx_train=idx_train, idx_test=idx_test)\n",
    "\n",
    "\n",
    "    max_iter = 1000\n",
    "    Y_t1 = Y_0.copy()\n",
    "    cost_t1 = alpha * np.trace(np.dot(np.dot(Y_t1.T, 1 - W1), Y_t1)) + (1 - alpha)*LA.norm(Y_t1 - Y_0)**2\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        Y_t2 = alpha * np.dot(W1, Y_t1) + (1 - alpha) * Y_0\n",
    "\n",
    "        cost_t2 = alpha * np.trace(np.dot(np.dot(Y_t2.T, 1 - W1), Y_t2)) + (1 - alpha)*LA.norm(Y_t2 - Y_0)**2\n",
    "        # print(\"---\")\n",
    "        # print(alpha)\n",
    "        Y_t1 = Y_t2.copy()\n",
    "        cost_t1 = cost_t2\n",
    "\n",
    "        if (cost_t2 - cost_t1) < (cost_t1 / 10000):\n",
    "            print(\"LNSM converged\")\n",
    "            break\n",
    "        if i == (max_iter - 1):\n",
    "            print(\"maximum iteration reached\")\n",
    "\n",
    "    Y1 = Y_t2.copy()\n",
    "\n",
    "    Y_t1 = Y_0.copy()\n",
    "    cost_t1 = alpha * np.trace(np.dot(np.dot(Y_t1.T, 1 - W2), Y_t1)) + (1 - alpha)*LA.norm(Y_t1 - Y_0)**2\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        Y_t2 = alpha * np.dot(W2, Y_t1) + (1 - alpha) * Y_0\n",
    "\n",
    "        cost_t2 = alpha * np.trace(np.dot(np.dot(Y_t2.T, 1 - W2), Y_t2)) + (1 - alpha)*LA.norm(Y_t2 - Y_0)**2\n",
    "        # print(\"---\")\n",
    "        # print(alpha)\n",
    "        # print(cost_t2)\n",
    "        Y_t1 = Y_t2.copy()\n",
    "        cost_t1 = cost_t2\n",
    "\n",
    "        if (cost_t2 - cost_t1) < (cost_t1 / 10000):\n",
    "            print(\"LNSM converged\")\n",
    "            break\n",
    "        if i == (max_iter - 1):\n",
    "            print(\"maximum iteration reached\")\n",
    "\n",
    "    Y2 = Y_t2.copy()\n",
    "\n",
    "\n",
    "\n",
    "    # Y1 = (1 - alpha) * np.dot(np.linalg.pinv(1 - alpha * W1), Y_0)\n",
    "    # Y2 = (1 - alpha) * np.dot(np.linalg.pinv(1 - alpha * W2), Y_0)\n",
    "    Y1_new = np.dot(W1_new, Y1)\n",
    "    Y2_new = np.dot(W2_new, Y2)\n",
    "\n",
    "    cost1 = alpha * np.trace(np.dot(np.dot(Y1.T, 1 - W1), Y1)) + (1 - alpha)*LA.norm(Y1 - Y_0)**2\n",
    "    cost2 = alpha * np.trace(np.dot(np.dot(Y2.T, 1 - W2), Y2)) + (1 - alpha)*LA.norm(Y2 - Y_0)**2\n",
    "    costmax = max(cost1, cost2)\n",
    "    theta1 = (costmax - cost1) / ((costmax - cost1) + (costmax - cost2))\n",
    "    theta2 = (costmax - cost2) / ((costmax - cost1) + (costmax - cost2))\n",
    "    # print(cost1)\n",
    "    # print(cost2)\n",
    "    # print(costmax - cost1)\n",
    "    # print(costmax - cost2)\n",
    "\n",
    "    Y_new = theta1 * Y1_new + theta2 * Y2_new\n",
    "    matrix_new = matrix.copy().astype(float)\n",
    "    matrix_new[:, idx_test] = Y_new.T\n",
    "    # print(sum(sum(matrix_new[:, idx_test])))\n",
    "    return matrix_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FeaturePreprocess(df_all, drug_nodes):\n",
    "    \n",
    "    drug_nodes_df = np.intersect1d(df_all.index, drug_nodes)\n",
    "    df = df_all.loc[drug_nodes_df]\n",
    "    _, q = df.shape\n",
    "    drug_nodes_diff = np.setdiff1d(drug_nodes, (df.index).tolist())\n",
    "    n = len(drug_nodes_diff)\n",
    "    df_diff = pd.DataFrame(np.zeros(n*q).reshape(n,q))\n",
    "    df_diff.index = drug_nodes_diff\n",
    "    df_diff.columns = df.columns\n",
    "    df_all = pd.concat([df, df_diff], axis = 0)\n",
    "    featureMat = df_all.loc[drug_nodes]\n",
    "    return np.array(featureMat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for cross validation and nested cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold(IDX1,IDX2,feature_matrix1,feature_matrix2,alpha,matrix):\n",
    "    # IDX1 target index, need to be evaluated\n",
    "    # IDX2 test index, masked\n",
    "    target_idx = IDX1\n",
    "    mask_idx = IDX2\n",
    "    Ground_Truth = matrix.copy()\n",
    "    side_effects_drug_relation_copy = matrix.copy()\n",
    "\n",
    "    # target_idx = IDX2\n",
    "    ### making all the links to predict as 0 ###############    \n",
    "    for i in range(len(mask_idx)):\n",
    "        side_effects_drug_relation_copy[:, mask_idx[i]] = 0\n",
    "    \n",
    "    m,n = side_effects_drug_relation_copy.shape\n",
    "\n",
    "    drug_idx = list(range(n))\n",
    "    existing_drug_idx = np.setdiff1d(drug_idx, mask_idx)\n",
    "\n",
    "    print('LNSM starts:')\n",
    "    if methodOption == \"LNSM_CMI\":\n",
    "        side_effects_drug_relation_fact = LNSM_CMI(matrix=matrix, feature_matrix1=feature_matrix1, feature_matrix2=feature_matrix2, alpha=alpha, idx_train=existing_drug_idx, idx_test=target_idx)\n",
    "    elif methodOption == \"LNSM_SMI\":\n",
    "        side_effects_drug_relation_fact = LNSM_SMI(matrix=matrix, feature_matrix1=feature_matrix1, feature_matrix2=feature_matrix2, alpha=alpha, idx_train=existing_drug_idx, idx_test=target_idx)\n",
    "    elif methodOption == \"LNSM_WMK1\":\n",
    "        side_effects_drug_relation_fact = LNSM(matrix=matrix, feature_matrix=feature_matrix1, alpha=alpha, idx_train=existing_drug_idx, \n",
    "        idx_test=target_idx)\n",
    "    elif methodOption == \"LNSM_WMK2\":\n",
    "        side_effects_drug_relation_fact = LNSM(matrix=matrix, feature_matrix=feature_matrix2, alpha=alpha, idx_train=existing_drug_idx, \n",
    "        idx_test=target_idx)\n",
    "    # side_effects_drug_relation_fact = perform_matrix_reconstruction(side_effects_drug_relation_copy, Gamma, weight_matrix, lmd, update_normalization)\n",
    "\n",
    "    # Set the out put of GNMF as prediction score\n",
    "    score = side_effects_drug_relation_fact.copy()\n",
    "\n",
    "    pr_auc_all = 0\n",
    "    roc_auc_all = 0\n",
    "\n",
    "\n",
    "    print(\"proportion of ground truth:\", sum(Ground_Truth[:, target_idx].ravel())/(Ground_Truth[:, target_idx].shape[0]*Ground_Truth[:, target_idx].shape[1]))\n",
    "\n",
    "    print('---evaluation---')\n",
    "\n",
    "    prec, recall, threshold = precision_recall_curve(Ground_Truth[:, target_idx].ravel(), score[:, target_idx].ravel())\n",
    "    pr_auc_all = auc(recall, prec)\n",
    "    roc_auc_all = roc_auc_score(Ground_Truth[:, target_idx].ravel(), score[:, target_idx].ravel())\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "    print(\"AUC-PR all:\", pr_auc_all)\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "    print(\"AUC-ROC all:\", roc_auc_all)\n",
    "\n",
    "    print(\"-----\")\n",
    "    return pr_auc_all, roc_auc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def innerfold(IDX1,IDX2,feature_matrix1,feature_matrix2,alpha,matrix):\n",
    "    # IDX1 target index, need to be evaluated\n",
    "    # IDX2 test index, masked\n",
    "\n",
    "    target_idx = IDX1\n",
    "    mask_idx = IDX2\n",
    "    Ground_Truth = matrix.copy()\n",
    "    side_effects_drug_relation_copy = matrix.copy()\n",
    "\n",
    "    # target_idx = IDX2\n",
    "    ### making all the links to predict as 0 ###############    \n",
    "    for i in range(len(mask_idx)):\n",
    "        side_effects_drug_relation_copy[:, mask_idx[i]] = 0\n",
    "    \n",
    "    m,n = side_effects_drug_relation_copy.shape\n",
    "\n",
    "    drug_idx = list(range(n))\n",
    "    existing_drug_idx = np.setdiff1d(drug_idx, mask_idx)\n",
    "    \n",
    "    # calculate the mean for each drug\n",
    "    mean_side_effect_score = (Ground_Truth.copy()[:, existing_drug_idx]).mean(axis=1)\n",
    "    score_mean = side_effects_drug_relation_copy.copy().astype(float)\n",
    "\n",
    "    # Set the prediction into mean\n",
    "    for i in range(m):\n",
    "        score_mean[i, mask_idx] =  mean_side_effect_score[i]\n",
    "\n",
    "    if methodOption == \"LNSM_CMI\":\n",
    "        side_effects_drug_relation_fact = LNSM_CMI(matrix=matrix, feature_matrix1=feature_matrix1, feature_matrix2=feature_matrix2, alpha=alpha, idx_train=existing_drug_idx, idx_test=target_idx)\n",
    "    elif methodOption == \"LNSM_SMI\":\n",
    "        side_effects_drug_relation_fact = LNSM_SMI(matrix=matrix, feature_matrix1=feature_matrix1, feature_matrix2=feature_matrix2, alpha=alpha, idx_train=existing_drug_idx, idx_test=target_idx)\n",
    "    elif methodOption == \"LNSM_WMK1\":\n",
    "        side_effects_drug_relation_fact = LNSM(matrix=matrix, feature_matrix=feature_matrix1, alpha=alpha, idx_train=existing_drug_idx, \n",
    "        idx_test=target_idx)\n",
    "    elif methodOption == \"LNSM_WMK2\":\n",
    "        side_effects_drug_relation_fact = LNSM(matrix=matrix, feature_matrix=feature_matrix2, alpha=alpha, idx_train=existing_drug_idx, \n",
    "        idx_test=target_idx)\n",
    "\n",
    "    # Set the out put of GNMF as prediction score\n",
    "    score = side_effects_drug_relation_fact.copy()\n",
    "\n",
    "    pr_auc_all = 0\n",
    "    roc_auc_all = 0\n",
    "\n",
    "    prec, recall, threshold = precision_recall_curve(Ground_Truth[:, target_idx].ravel(), score[:, target_idx].ravel())\n",
    "    pr_auc_all = auc(recall, prec)\n",
    "\n",
    "    return pr_auc_all, roc_auc_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotfold(IDX1,IDX2,feature_matrix1,feature_matrix2,alpha,matrix):\n",
    "    # IDX1 target index, need to be evaluated\n",
    "    # IDX2 test index, masked\n",
    "\n",
    "    target_idx = IDX1\n",
    "    mask_idx = IDX2\n",
    "    Ground_Truth = matrix.copy()\n",
    "    side_effects_drug_relation_copy = matrix.copy()\n",
    "\n",
    "    # target_idx = IDX2\n",
    "    ### making all the links to predict as 0 ###############    \n",
    "    for i in range(len(mask_idx)):\n",
    "        side_effects_drug_relation_copy[:, mask_idx[i]] = 0\n",
    "    \n",
    "    m,n = side_effects_drug_relation_copy.shape\n",
    "\n",
    "    drug_idx = list(range(n))\n",
    "    existing_drug_idx = np.setdiff1d(drug_idx, mask_idx)\n",
    "    \n",
    "    print('LNSM starts:')\n",
    "    if methodOption == \"LNSM_CMI\":\n",
    "        side_effects_drug_relation_fact = LNSM_CMI(matrix=matrix, feature_matrix1=feature_matrix1, feature_matrix2=feature_matrix2, alpha=alpha, idx_train=existing_drug_idx, idx_test=target_idx)\n",
    "    elif methodOption == \"LNSM_SMI\":\n",
    "        side_effects_drug_relation_fact = LNSM_SMI(matrix=matrix, feature_matrix1=feature_matrix1, feature_matrix2=feature_matrix2, alpha=alpha, idx_train=existing_drug_idx, idx_test=target_idx)\n",
    "    elif methodOption == \"LNSM_WMK1\":\n",
    "        side_effects_drug_relation_fact = LNSM(matrix=matrix, feature_matrix=feature_matrix1, alpha=alpha, idx_train=existing_drug_idx, \n",
    "        idx_test=target_idx)\n",
    "    elif methodOption == \"LNSM_WMK2\":\n",
    "        side_effects_drug_relation_fact = LNSM(matrix=matrix, feature_matrix=feature_matrix2, alpha=alpha, idx_train=existing_drug_idx, \n",
    "        idx_test=target_idx)\n",
    "    # side_effects_drug_relation_fact = perform_matrix_reconstruction(side_effects_drug_relation_copy, Gamma, weight_matrix, lmd, update_normalization)\n",
    "\n",
    "    # Set the out put of GNMF as prediction score\n",
    "    score = side_effects_drug_relation_fact.copy()\n",
    "\n",
    "    pr_auc_all = 0\n",
    "    roc_auc_all = 0\n",
    "\n",
    "\n",
    "    print(\"proportion of ground truth:\", sum(Ground_Truth[:, target_idx].ravel())/(Ground_Truth[:, target_idx].shape[0]*Ground_Truth[:, target_idx].shape[1]))\n",
    "\n",
    "    print('---evaluation---')\n",
    "\n",
    "    prec, recall, prthreshold = precision_recall_curve(Ground_Truth[:, target_idx].ravel(), score[:, target_idx].ravel())\n",
    "    pr_auc_all = auc(recall, prec)\n",
    "    \n",
    "    fpr, tpr, rocthreshold = metrics.roc_curve(Ground_Truth[:, target_idx].ravel(), score[:, target_idx].ravel())\n",
    "    roc_auc_all = auc(fpr, tpr)\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "    print(\"AUC-PR all:\", pr_auc_all)\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "    print(\"AUC-ROC all:\", roc_auc_all)\n",
    "\n",
    "    print(\"-----\")\n",
    "\n",
    "    Out1 = pd.DataFrame([prec, recall, prthreshold])\n",
    "    Out2 = pd.DataFrame([fpr, tpr, rocthreshold])\n",
    "    return Out1, Out2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for assigning arguments of CV and nested CV, as well as finding the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setvar_tune(size):\n",
    "# set var for hyper pars tuning size is the hyper par size ALL_...\n",
    "\n",
    "    global ALL_AUCPR_all\n",
    "    global ALL_AUROC_all\n",
    "\n",
    "    ALL_AUCPR_all = np.zeros(size)\n",
    "    ALL_AUROC_all = np.zeros(size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setvar_cv(FOLDS):\n",
    "# set var for cv \n",
    "\n",
    "    global AUC_roc_all\n",
    "    global AUC_pr_all\n",
    "\n",
    "    \n",
    "    AUC_roc_all = np.zeros(FOLDS)\n",
    "    AUC_pr_all = np.zeros(FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asgvar_tune(idx, results):\n",
    "    # assign var for cv from results\n",
    "    # f: size of hyper pars\n",
    "    ALL_AUCPR_all[idx] = results[0]\n",
    "    ALL_AUROC_all[idx] = results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asgvar_cv(f, results):\n",
    "    # assign var for cv from results\n",
    "    # f: size of hyper pars\n",
    "\n",
    "    AUC_pr_all[f] = results[0]\n",
    "    AUC_roc_all[f] = results[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_results(tuneVar):\n",
    "    idx = np.argmax(ALL_AUCPR_all)\n",
    "    Var = tuneVar[idx]\n",
    "    Value = ALL_AUCPR_all[idx]\n",
    "\n",
    "    print(\"best hyperpar: \", Var)\n",
    "    print(\"AUPRC: \", Value)\n",
    "\n",
    "    return Var, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setvar_besttune(innerfolds):\n",
    "    global besttunevalue\n",
    "    global besttunevar\n",
    "    besttunevalue = np.zeros(innerfolds) # best metric value\n",
    "    besttunevar = np.zeros(innerfolds) # the value of best var\n",
    "    besttunevar = besttunevar.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asg_besttune(f, value, var):\n",
    "    besttunevalue[f] = value\n",
    "    besttunevar[f] = var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def besttune():\n",
    "    idx = np.argmax(besttunevalue)\n",
    "    value = besttunevalue[idx]\n",
    "    var = besttunevar[idx]\n",
    "    return value, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_results():\n",
    "    \n",
    "    print(\"-----------\")\n",
    "\n",
    "    print(\"Mean AUC_pr_all\", AUC_pr_all.mean(),\" \", \"Standard Deviation:\", AUC_pr_all.std())\n",
    "    print(\"Mean AUC_roc_all\", AUC_roc_all.mean(),\" \", \"Standard Deviation:\", AUC_roc_all.std())\n",
    "\n",
    "    print(\"-----------\")\n",
    "    results = np.array([AUC_pr_all, AUC_roc_all])\n",
    "    return results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for parallel computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tuning_loop(innermatrix, idx_train_inner, idx_test_inner, feature_matrix_inner1, feature_matrix_inner2, hyperparList, i):\n",
    "    a = hyperparList[i]\n",
    "    idx_target_inner = idx_test_inner\n",
    "    results = innerfold(idx_target_inner,idx_test_inner,feature_matrix1=feature_matrix_inner1,feature_matrix2=feature_matrix_inner2,alpha=a,matrix=innermatrix)\n",
    "    asgvar_tune(i, results=results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(method_option,alpha=0.8,Validation=\"nested_cv\",sets=\"intersect\",a=0.8):\n",
    "    random.seed(1949) # for dataset split\n",
    "    np.random.seed(1949) # for matrix initialization\n",
    "    option(method_option)\n",
    "\n",
    "    random.seed(1949) # for dataset split\n",
    "    np.random.seed(1949) # for matrix initialization\n",
    "    df = pd.read_csv(\"data/side-effect-and-drug_name_upper.tsv\",sep = \"\\t\")\n",
    "    drug_id = df[\"drugbank_id\"] # put col of df in var\n",
    "    drug_name = df[\"drugbank_name\"]\n",
    "    side_effect = df[\"side_effect_name\"]\n",
    "    \n",
    "    \n",
    "    edgelist1 = zip(side_effect, drug_name)\n",
    "    ##making Biparite Graph##\n",
    "    B = nx.DiGraph()\n",
    "    B.add_nodes_from(side_effect,bipartite = 0)\n",
    "    B.add_nodes_from(drug_name,bipartite = 1)\n",
    "    B.add_edges_from(edgelist1)\n",
    "    # B.add_weighted_edges_from(edgelist2)\n",
    "    drug_nodes = {n for n, d in B.nodes(data=True) if d['bipartite']==1}\n",
    "    side_effect_nodes = {n for n, d in B.nodes(data=True) if d['bipartite']==0}\n",
    "    drug_nodes = list(drug_nodes)\n",
    "    drug_nodes.sort()\n",
    "    side_effect_nodes = list(side_effect_nodes)\n",
    "    side_effect_nodes.sort()\n",
    "    ###Getting the Bi-Adjacency matrix between side effects and drugs ###################\n",
    "    matrix_all = biadjacency_matrix(B, row_order = side_effect_nodes, column_order = drug_nodes) # create biadjacency matrix for drug side effect graph\n",
    "    matrix_all = matrix_all.A\n",
    "    m_all,n_all = matrix_all.shape # number of side effect # number of drug\n",
    "    \n",
    "    \n",
    "    ### Setting validation set / training set / testing set ###\n",
    "    validate_sz = int(0.25 * n_all)\n",
    "    IDX_all = list(range(n_all))\n",
    "    random.shuffle(IDX_all)\n",
    "    IDX_validate = sorted(IDX_all[0:validate_sz])\n",
    "    print(\"first few validation set idx:\")\n",
    "    print(IDX_validate[0:10])\n",
    "    IDX_validate_diff = np.setdiff1d(IDX_all, IDX_validate)\n",
    "    matrix = matrix_all[:, IDX_validate_diff].copy()\n",
    "\n",
    "    df1 = pd.read_csv(\"data/intersection_DGIdb_mat.tsv\",sep = \"\\t\")\n",
    "    df2 = pd.read_csv(\"data/intersection_Fingerprint_mat.tsv\",sep = \"\\t\")\n",
    "    featureMat1_all = FeaturePreprocess(df1, drug_nodes=drug_nodes)\n",
    "    featureMat2_all = FeaturePreprocess(df2, drug_nodes=drug_nodes)\n",
    "    featureMat1 = featureMat1_all[IDX_validate_diff, :].copy()\n",
    "    featureMat2 = featureMat2_all[IDX_validate_diff, :].copy()\n",
    "    \n",
    "    \n",
    "    non_zero_idx_union = np.hstack(np.where(~((featureMat1.sum(1) == 0) & (featureMat2.sum(1) == 0))))\n",
    "    non_zero_idx_missing = np.hstack(np.where(~(~(featureMat1.sum(1) == 0) & ~(featureMat2.sum(1) == 0))))\n",
    "    non_zero_idx_intersect = np.hstack(np.where(~(featureMat1.sum(1) == 0) & ~(featureMat2.sum(1) == 0)))\n",
    "    if sets == \"union\":\n",
    "        # union\n",
    "        matrix = matrix[:, non_zero_idx_union].copy()\n",
    "        featureMat1 = featureMat1[non_zero_idx_union, :].copy()\n",
    "        featureMat2 = featureMat2[non_zero_idx_union, :].copy()\n",
    "    elif sets == \"intersect\":\n",
    "        # intersect\n",
    "        non_zero_idx_intersect_all = np.hstack(np.where(~(featureMat1_all.sum(1) == 0) & ~(featureMat2_all.sum(1) == 0)))\n",
    "    \n",
    "        matrix_all = matrix_all[:, non_zero_idx_intersect_all].copy()\n",
    "        featureMat1_all = featureMat1_all[non_zero_idx_intersect_all, :].copy()\n",
    "        featureMat2_all = featureMat2_all[non_zero_idx_intersect_all, :].copy()\n",
    "    \n",
    "        matrix = matrix[:, non_zero_idx_intersect].copy()\n",
    "        featureMat1 = featureMat1[non_zero_idx_intersect, :].copy()\n",
    "        featureMat2 = featureMat2[non_zero_idx_intersect, :].copy()\n",
    "    \n",
    "        IDX_validate = np.setdiff1d(non_zero_idx_intersect_all, IDX_validate_diff)\n",
    "        IDX_validate_diff = np.setdiff1d(non_zero_idx_intersect_all, IDX_validate)\n",
    "    \n",
    "        drug_nodes_intersect_all = np.array(drug_nodes)[non_zero_idx_intersect_all]\n",
    "        drug_nodes_intersect_validate_diff = np.array(drug_nodes)[IDX_validate_diff]\n",
    "        drug_nodes_intersect_validate = np.array(drug_nodes)[IDX_validate]\n",
    "    \n",
    "        IDX_validate = np.array([x for x in range(len(drug_nodes_intersect_all)) if drug_nodes_intersect_all[x] in drug_nodes_intersect_validate])\n",
    "        IDX_validate_diff = np.array([x for x in range(len(drug_nodes_intersect_all)) if drug_nodes_intersect_all[x] in drug_nodes_intersect_validate_diff])\n",
    "    \n",
    "    m,n = matrix.shape # number of side effect # number of drug\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    random.seed(1949) # for dataset split\n",
    "    np.random.seed(1949) # for matrix initialization\n",
    "    start_time = time.time()\n",
    "\n",
    "\n",
    "\n",
    "    FOLDS = 5\n",
    "    innerFOLDS = 4\n",
    "    ####for test sets####\n",
    "    setvar_cv(FOLDS)\n",
    "\n",
    "    sz = n\n",
    "    IDX = list(range(sz))\n",
    "    fsz = int(sz/FOLDS)\n",
    "    random.shuffle(IDX)\n",
    "    IDX = np.array(IDX)\n",
    "    offset = 0\n",
    "\n",
    "    innersz = sz - fsz\n",
    "    innerIDX = list(range(innersz))\n",
    "    random.shuffle(innerIDX)\n",
    "    innerIDX = np.array(innerIDX)\n",
    "    innerfsz = int(innersz / innerFOLDS)\n",
    "    inneroffset = 0\n",
    "    # setvar_cv(FOLDS=FOLDS)\n",
    "    if Validation == \"nested_cv\":\n",
    "        print(\"---------- nested cv start ----------\")\n",
    "        for f in range(FOLDS):  # range(FOLDS):\n",
    "            offset = 0 + f*fsz\n",
    "            idx_test = IDX[offset:offset + fsz]\n",
    "    \n",
    "            idx_train = IDX[np.setdiff1d(np.arange(len(IDX)), np.arange(offset,offset + fsz))]\n",
    "            print(\"Fold:\",f)\n",
    "            innermatrix = matrix[:, idx_train]\n",
    "            innerfeatureMat1 = featureMat1[idx_train, :].copy()\n",
    "            innerfeatureMat2 = featureMat2[idx_train, :].copy()\n",
    "            # print(type(weight_matrix1_inner))\n",
    "    \n",
    "            setvar_besttune(innerFOLDS)\n",
    "    \n",
    "            for innerf in range(innerFOLDS):\n",
    "                idx_test_inner = innerIDX[inneroffset:inneroffset + innerfsz]\n",
    "                idx_train_inner = innerIDX[np.array(np.setdiff1d(np.arange(len    (idx_train)), np.arange(inneroffset,inneroffset + innerfsz)))]\n",
    "    \n",
    "                print(\"Inner Fold:\", innerf)\n",
    "    \n",
    "                alpha = np.arange(0.1, 1, 0.05).tolist()\n",
    "                hyperparList = alpha\n",
    "                setvar_tune(len(hyperparList))\n",
    "    \n",
    "                with parallel_backend('threading'):\n",
    "                    Parallel(n_jobs=20)(delayed(tuning_loop)(innermatrix = innermatrix, idx_train_inner = idx_train_inner, \n",
    "                        idx_test_inner = idx_test_inner, feature_matrix_inner1= innerfeatureMat1, \\\n",
    "                            feature_matrix_inner2=innerfeatureMat2, hyperparList = hyperparList, i = i) \\\n",
    "                                    for i in range(len(hyperparList)))\n",
    "    \n",
    "                # tuning_plot(tuneVar=C, tune=\"C\")\n",
    "                hyperpars, evalValue = tuning_results(tuneVar=hyperparList)\n",
    "    \n",
    "                asg_besttune(innerf, value=evalValue, var=hyperpars)\n",
    "                    \n",
    "            _, bestHyperPars = besttune()\n",
    "                \n",
    "    \n",
    "            print(\"--- tuning end ---\")\n",
    "            a = bestHyperPars\n",
    "    \n",
    "                \n",
    "            # idx_target = np.intersect1d(idx_test, WMK_non_zero_idx_intersect)\n",
    "            idx_target = idx_test\n",
    "            print('target size:', len(idx_target))\n",
    "    \n",
    "            print(\"------ lambda: \", a, \"------\")\n",
    "    \n",
    "            results = fold(idx_target,idx_test,featureMat1,featureMat2,alpha=a,matrix=matrix)\n",
    "            asgvar_cv(f=f, results=results)\n",
    "                \n",
    "            \n",
    "        out_mean, out = cv_results()\n",
    "        return out_mean, out\n",
    "    elif Validation == \"cv\":\n",
    "        print(\"---------- cv start ----------\")\n",
    "        setvar_besttune(FOLDS)\n",
    "        for f in range(FOLDS):  # range(FOLDS):\n",
    "            offset = 0 + f*fsz\n",
    "            idx_test = IDX[offset:offset + fsz]\n",
    "            idx_train = IDX[np.setdiff1d(np.arange(len(IDX)), np.arange(offset,offset + fsz))]\n",
    "\n",
    "            print(\"Fold:\",f)\n",
    "\n",
    "\n",
    "            alpha = np.arange(0.1, 1, 0.05).tolist()\n",
    "            hyperparList = alpha\n",
    "            setvar_tune(len(hyperparList))\n",
    "    \n",
    "            with parallel_backend('threading'):\n",
    "                Parallel(n_jobs=20)(delayed(tuning_loop)(innermatrix = matrix, idx_train_inner = idx_train, idx_test_inner = idx_test, \\\n",
    "                    feature_matrix_inner1= featureMat1, feature_matrix_inner2= featureMat2, hyperparList = hyperparList, i = i) \\\n",
    "                    for i in range(len(hyperparList)))\n",
    "    \n",
    "            # tuning_plot(tuneVar=C, tune=\"C\")\n",
    "            hyperpars, evalValue = tuning_results(tuneVar=hyperparList)\n",
    "    \n",
    "            asg_besttune(f, value=evalValue, var=hyperpars)                \n",
    "\n",
    "                    \n",
    "        print(\"--- tuning end ---\")\n",
    "        # cv_results()\n",
    "        _, bestHyperPars = besttune()\n",
    "    \n",
    "    elif Validation == \"Validation\":\n",
    "\n",
    "        idx_test = IDX_validate\n",
    "        idx_train = IDX_validate_diff\n",
    "        idx_target = idx_test\n",
    "        print('target size:', len(idx_target))\n",
    "        print(\"------ a: \", a, \"------\")\n",
    "    \n",
    "        results = fold(idx_target,idx_test,feature_matrix1=featureMat1_all, feature_matrix2=featureMat2_all,alpha=a,matrix=matrix_all)\n",
    "        return\n",
    "    elif Validation == \"plot\":\n",
    "    \n",
    "        idx_test = IDX_validate\n",
    "        idx_train = IDX_validate_diff\n",
    "        idx_target = idx_test\n",
    "        print('target size:', len(idx_target))\n",
    "        print(\"------ a: \", a, \"------\")\n",
    "    \n",
    "        pr, roc = plotfold(idx_target,idx_test,feature_matrix1=featureMat1_all,feature_matrix2=featureMat2_all,alpha=a,matrix=matrix_all)\n",
    "        \n",
    "        return pr, roc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Nested CV and CV for LNSM-RLN family"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Nested CV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the nested CV for feature DGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option = \"LNSM_CMI\", Validation=\"nested_cv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the nested CV for feature Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option = \"LNSM_SMI\", Validation=\"nested_cv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the nested CV for feature DGI and Chem combine by CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option = \"LNSM_WMK1\", Validation=\"nested_cv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the nested CV for feature DGI and Chem combine by SMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option = \"LNSM_WMK2\", Validation=\"nested_cv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. CV to tune hyperparameters for independent test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running CV for DGI. The best hyperparameters are $\\alpha=0.15$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option = \"LNSM_CMI\",Validation=\"cv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running CV for DGI. The best hyperparameters are $\\alpha=0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option = \"LNSM_SMI\",Validation=\"cv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running CV for DGI. The best hyperparameters are $\\alpha=0.1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option = \"LNSM_WMK1\",Validation=\"cv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running CV for DGI. The best hyperparameters are $\\alpha=0.15$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option = \"LNSM_WMK2\",Validation=\"cv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Independent test set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DGI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option = \"LNSM_CMI\", Validation=\"Validation\", a=0.15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option = \"LNSM_SMI\", Validation=\"Validation\", a=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DGI and Chem combine by CMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option = \"LNSM_WMK1\", Validation=\"Validation\", a=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DGI and Chem combine by SMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main(method_option = \"LNSM_WMK2\", Validation=\"Validation\", a=0.15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * Save data for PR and ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LNSM_CMI_RLN_pr, LNSM_CMI_RLN_roc = \\\n",
    "    main(method_option=\"LNSM_CMI\", Validation=\"plot\", a=0.15)            \n",
    "LNSM_CMI_RLN_pr.T.to_csv(\"Figs/LNSM_CMI_RLN_pr.csv\", index=False)\n",
    "LNSM_CMI_RLN_roc.T.to_csv(\"Figs/LNSM_CMI_RLN_roc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LNSM_SMI_RLN_pr, LNSM_SMI_RLN_roc = \\\n",
    "    main(method_option=\"LNSM_SMI\", Validation=\"plot\", a=0.1)\n",
    "LNSM_SMI_RLN_pr.T.to_csv(\"Figs/LNSM_SMI_RLN_pr.csv\", index=False)\n",
    "LNSM_SMI_RLN_roc.T.to_csv(\"Figs/LNSM_SMI_RLN_roc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LNSM_WMK1_RLN_pr, LNSM_WMK1_RLN_roc = \\\n",
    "    main(method_option=\"LNSM_WMK1\", Validation=\"plot\", a=0.1)\n",
    "LNSM_WMK1_RLN_pr.T.to_csv(\"Figs/LNSM_WMK1_RLN_pr.csv\", index=False)\n",
    "LNSM_WMK1_RLN_roc.T.to_csv(\"Figs/LNSM_WMK1_RLN_roc.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LNSM_WMK2_RLN_pr, LNSM_WMK2_RLN_roc = \\\n",
    "    main(method_option=\"LNSM_WMK2\", Validation=\"plot\", a=0.15)\n",
    "LNSM_WMK2_RLN_pr.T.to_csv(\"Figs/LNSM_WMK2_RLN_pr.csv\", index=False)\n",
    "LNSM_WMK2_RLN_roc.T.to_csv(\"Figs/LNSM_WMK2_RLN_roc.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 ('tf-2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ac95e2fd4e3c95fb3fb1f7e38114c393d9f202cef380ef2efc5a4245619d104b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
